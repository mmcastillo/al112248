{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODxABTA5na8CHjBGiCoDYZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmcastillo/al112248/blob/main/modelo1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he1raG8TN9jT",
        "outputId": "36b783fe-7df6-4588-d5a2-d7ad0fba8079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (5.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install natsort"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/');\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate\n",
        "from scipy import ndimage\n",
        "import random\n",
        "import natsort\n",
        "import glob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRIWbDUTQFTZ",
        "outputId": "eb930c3d-e863-4d5c-d0a6-cb259d9c8383"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/train/50p_rand_50n/imgs/';\n",
        "train_mask_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/train/50p_rand_50n/masks/';\n",
        "train_img_list = os.listdir(train_img_dir)\n",
        "train_img_list = natsort.natsorted(train_img_list)\n",
        "train_mask_list = os.listdir(train_mask_dir)\n",
        "train_mask_list = natsort.natsorted(train_mask_list)\n",
        "\n",
        "val_img_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/val/imgs/';\n",
        "val_mask_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/val/masks/';\n",
        "val_img_list = os.listdir(val_img_dir)\n",
        "val_img_list = natsort.natsorted(val_img_list)\n",
        "val_mask_list = os.listdir(val_mask_dir)\n",
        "val_mask_list = natsort.natsorted(val_mask_list)"
      ],
      "metadata": {
        "id": "MruxLoBYQqFh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(img_dir, img_list):\n",
        "    images=[]\n",
        "    for i, image_name in enumerate(img_list):    \n",
        "        if (image_name.split('.')[1] == 'npy'):\n",
        "            \n",
        "            image = np.load(img_dir+image_name)\n",
        "                      \n",
        "            images.append(image)\n",
        "    images = np.array(images)\n",
        "    \n",
        "    return(images)"
      ],
      "metadata": {
        "id": "bTAaIf_5QPqC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U8qqs4WJwYwE"
      },
      "outputs": [],
      "source": [
        "def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n",
        "\n",
        "    L = len(img_list)\n",
        "\n",
        "    #keras needs the generator infinite, so we will use while true  \n",
        "    while True:\n",
        "\n",
        "        batch_start = 0\n",
        "        batch_end = batch_size\n",
        "\n",
        "        while batch_start < L:\n",
        "            limit = min(batch_end, L)\n",
        "                       \n",
        "            X = load_img(img_dir, img_list[batch_start:limit])\n",
        "            Y = load_img(mask_dir, mask_list[batch_start:limit])\n",
        "\n",
        "            X = X.astype(np.float32)  \n",
        "            Y = Y.astype(np.float32)\n",
        "\n",
        "            #I = img_list[batch_start:limit]\n",
        "            #M = mask_list[batch_start:limit]\n",
        "\n",
        "\n",
        "            yield (X,Y)#,I,M) #a tuple with two numpy arrays with batch_size samples\n",
        "           \n",
        "            batch_start += batch_size   \n",
        "            batch_end += batch_size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "\n",
        "train_img_datagen = imageLoader(train_img_dir, train_img_list, \n",
        "                                train_mask_dir, train_mask_list,batch_size)\n",
        "\n",
        "val_img_datagen = imageLoader(val_img_dir, val_img_list, \n",
        "                                val_mask_dir, val_mask_list,batch_size)\n"
      ],
      "metadata": {
        "id": "gwccjU68Qr7L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img,mask = train_img_datagen.__next__()\n",
        "print(img.shape)\n",
        "print(mask.shape)\n",
        "print(np.unique(mask))\n",
        "\n",
        "#Encuentra los patches 3D donde las máscaras contienen valores 1 y 0 (donde hay aneurisams)\n",
        "#if np.unique(mask).shape[0]  == 2:\n",
        "  #for i in range(mask.shape[0]):\n",
        "    #if np.unique(mask[i,:,:,:]).shape[0] == 2: \n",
        "      #n_patch_aneurisma = i\n",
        "      #print(f'En el patch número {n_patch_aneurisma+1} se encuentra el aneurisma')\n",
        "      #n_imagenes_aneurismas=[]\n",
        "      #for j in range(mask.shape[1]):\n",
        "        #if np.unique(mask[n_patch_aneurisma,j,:,:]).shape[0] == 2:\n",
        "          #print(f'En las imagenes {j+1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KHHIyA0zdAl",
        "outputId": "fa9d7af4-6781-4909-b62f-a4936cbf95bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 64, 64, 64, 1)\n",
            "(4, 64, 64, 64, 1)\n",
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bv3JM39CV_tU"
      },
      "outputs": [],
      "source": [
        "def conv_block(input, num_filters):\n",
        "    x = Conv3D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)   #Not in the original network. \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv3D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)  #Not in the original network\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#Encoder block: Conv block followed by maxpooling\n",
        "\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPooling3D((2, 2, 2))(x)\n",
        "    return x, p   \n",
        "\n",
        "#Decoder block\n",
        "#skip features gets input from encoder for concatenation\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "#Build Unet using the blocks\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 16)\n",
        "    s2, p2 = encoder_block(p1, 32)\n",
        "    s3, p3 = encoder_block(p2, 64)\n",
        "    s4, p4 = encoder_block(p3, 128)\n",
        "\n",
        "    b1 = conv_block(p4, 256) #Bridge\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 128)\n",
        "    d2 = decoder_block(d1, s3, 64)\n",
        "    d3 = decoder_block(d2, s2, 32)\n",
        "    d4 = decoder_block(d3, s1, 16)\n",
        "\n",
        "    activation = 'sigmoid'\n",
        "\n",
        "    outputs = Conv3D(1, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n",
        "    print(f'activation function: {activation}')\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6qkE9MIgBYB",
        "outputId": "2ffe0ccd-9b4b-41d9-de10-e25356063641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activation function: sigmoid\n",
            "model input shape: (None, 64, 64, 64, 1)\n"
          ]
        }
      ],
      "source": [
        "model = build_unet((64, 64, 64, 1))\n",
        "print(f'model input shape: {model.input_shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ant9LozBclBY",
        "outputId": "2621b93d-7f0f-4b2d-f15c-8415101bc1e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation-models-3D\n",
            "  Downloading segmentation_models_3D-1.0.4-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-3D) (2.9.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting classification-models-3D>=1.0.6\n",
            "  Downloading classification_models_3D-1.0.6-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->segmentation-models-3D) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->segmentation-models-3D) (3.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (3.19.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.50.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (4.1.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.15.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (14.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (21.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.27.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.1.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->segmentation-models-3D) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->segmentation-models-3D) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.14.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow>=2.8.0->segmentation-models-3D) (3.0.9)\n",
            "Installing collected packages: keras-applications, classification-models-3D, segmentation-models-3D\n",
            "Successfully installed classification-models-3D-1.0.6 keras-applications-1.0.8 segmentation-models-3D-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation-models-3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4-ffnnX2lDT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e8fe42-8182-446c-f2e5-5b49e4360725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ],
      "source": [
        "from segmentation_models_3D.losses import BinaryCELoss\n",
        "import segmentation_models_3D as sm\n",
        "from keras import backend as K\n",
        "\n",
        "'''\n",
        "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
        "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
        "'''\n",
        "#dice_loss = sm.losses.DiceLoss()\n",
        "#focal_loss = sm.losses.BinaryFocalLoss()\n",
        "#total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
        "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
        "\n",
        "iou = tf.keras.metrics.MeanIoU(num_classes=2)\n",
        "\n",
        "metrics = [iou, sm.metrics.FScore(), sm.metrics.Precision(), sm.metrics.Recall()]\n",
        "#jaccard_loss = sm.losses.JaccardLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg8cd8WeixXu",
        "outputId": "129a8fe3-4313-4d3c-c1ff-e4cefb61347e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 64, 64,  0           []                               \n",
            "                                 1)]                                                              \n",
            "                                                                                                  \n",
            " conv3d (Conv3D)                (None, 64, 64, 64,   448         ['input_1[0][0]']                \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 64, 64, 64,   64         ['conv3d[0][0]']                 \n",
            " alization)                     16)                                                               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 64, 64, 64,   0           ['batch_normalization[0][0]']    \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_1 (Conv3D)              (None, 64, 64, 64,   6928        ['activation[0][0]']             \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 64, 64, 64,   64         ['conv3d_1[0][0]']               \n",
            " rmalization)                   16)                                                               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 64, 64, 64,   0           ['batch_normalization_1[0][0]']  \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " max_pooling3d (MaxPooling3D)   (None, 32, 32, 32,   0           ['activation_1[0][0]']           \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_2 (Conv3D)              (None, 32, 32, 32,   13856       ['max_pooling3d[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 32,   128        ['conv3d_2[0][0]']               \n",
            " rmalization)                   32)                                                               \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32, 32, 32,   0           ['batch_normalization_2[0][0]']  \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_3 (Conv3D)              (None, 32, 32, 32,   27680       ['activation_2[0][0]']           \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 32,   128        ['conv3d_3[0][0]']               \n",
            " rmalization)                   32)                                                               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 32, 32,   0           ['batch_normalization_3[0][0]']  \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " max_pooling3d_1 (MaxPooling3D)  (None, 16, 16, 16,   0          ['activation_3[0][0]']           \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_4 (Conv3D)              (None, 16, 16, 16,   55360       ['max_pooling3d_1[0][0]']        \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 16,   256        ['conv3d_4[0][0]']               \n",
            " rmalization)                   64)                                                               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 16, 16, 16,   0           ['batch_normalization_4[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv3d_5 (Conv3D)              (None, 16, 16, 16,   110656      ['activation_4[0][0]']           \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 16,   256        ['conv3d_5[0][0]']               \n",
            " rmalization)                   64)                                                               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 16,   0           ['batch_normalization_5[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " max_pooling3d_2 (MaxPooling3D)  (None, 8, 8, 8, 64)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv3d_6 (Conv3D)              (None, 8, 8, 8, 128  221312      ['max_pooling3d_2[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 8, 8, 8, 128  512        ['conv3d_6[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 8, 8, 8, 128  0           ['batch_normalization_6[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_7 (Conv3D)              (None, 8, 8, 8, 128  442496      ['activation_6[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 8, 8, 8, 128  512        ['conv3d_7[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 8, 8, 8, 128  0           ['batch_normalization_7[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling3d_3 (MaxPooling3D)  (None, 4, 4, 4, 128  0          ['activation_7[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_8 (Conv3D)              (None, 4, 4, 4, 256  884992      ['max_pooling3d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 4, 4, 4, 256  1024       ['conv3d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 4, 4, 4, 256  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_9 (Conv3D)              (None, 4, 4, 4, 256  1769728     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 4, 4, 4, 256  1024       ['conv3d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 4, 4, 4, 256  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_transpose (Conv3DTransp  (None, 8, 8, 8, 128  262272     ['activation_9[0][0]']           \n",
            " ose)                           )                                                                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8, 8, 8, 256  0           ['conv3d_transpose[0][0]',       \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv3d_10 (Conv3D)             (None, 8, 8, 8, 128  884864      ['concatenate[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 8, 8, 8, 128  512        ['conv3d_10[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 8, 8, 8, 128  0           ['batch_normalization_10[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_11 (Conv3D)             (None, 8, 8, 8, 128  442496      ['activation_10[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 8, 8, 8, 128  512        ['conv3d_11[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 8, 8, 8, 128  0           ['batch_normalization_11[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_transpose_1 (Conv3DTran  (None, 16, 16, 16,   65600      ['activation_11[0][0]']          \n",
            " spose)                         64)                                                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 16, 16, 16,   0           ['conv3d_transpose_1[0][0]',     \n",
            "                                128)                              'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv3d_12 (Conv3D)             (None, 16, 16, 16,   221248      ['concatenate_1[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 16,   256        ['conv3d_12[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 16,   0           ['batch_normalization_12[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv3d_13 (Conv3D)             (None, 16, 16, 16,   110656      ['activation_12[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 16,   256        ['conv3d_13[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 16,   0           ['batch_normalization_13[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv3d_transpose_2 (Conv3DTran  (None, 32, 32, 32,   16416      ['activation_13[0][0]']          \n",
            " spose)                         32)                                                               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 32, 32, 32,   0           ['conv3d_transpose_2[0][0]',     \n",
            "                                64)                               'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv3d_14 (Conv3D)             (None, 32, 32, 32,   55328       ['concatenate_2[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 32, 32,   128        ['conv3d_14[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_14[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_15 (Conv3D)             (None, 32, 32, 32,   27680       ['activation_14[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 32, 32, 32,   128        ['conv3d_15[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_15[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_transpose_3 (Conv3DTran  (None, 64, 64, 64,   4112       ['activation_15[0][0]']          \n",
            " spose)                         16)                                                               \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 64, 64, 64,   0           ['conv3d_transpose_3[0][0]',     \n",
            "                                32)                               'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv3d_16 (Conv3D)             (None, 64, 64, 64,   13840       ['concatenate_3[0][0]']          \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 64, 64, 64,   64         ['conv3d_16[0][0]']              \n",
            " ormalization)                  16)                                                               \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_16[0][0]'] \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_17 (Conv3D)             (None, 64, 64, 64,   6928        ['activation_16[0][0]']          \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 64, 64, 64,   64         ['conv3d_17[0][0]']              \n",
            " ormalization)                  16)                                                               \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_17[0][0]'] \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_18 (Conv3D)             (None, 64, 64, 64,   17          ['activation_17[0][0]']          \n",
            "                                1)                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,650,801\n",
            "Trainable params: 5,647,857\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "LR = 0.01\n",
            "BinaryCrossentropy\n"
          ]
        }
      ],
      "source": [
        "LR = 0.01\n",
        "optim = keras.optimizers.Adam(LR)\n",
        "\n",
        "loss = 'BinaryCrossentropy'\n",
        "\n",
        "model.compile(optimizer=optim, loss=loss ,metrics = metrics)\n",
        "print(model.summary())\n",
        "print(f'LR = {LR}')\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5n_rIbVlQ5I",
        "outputId": "52b0d8a7-3a25-4c90-cfb6-c735678828b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.0064 - mean_io_u: 0.4993 - f1-score: 0.0235 - precision: 0.0508 - recall: 0.3235 - val_loss: 1.2317e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.5837e-06 - val_precision: 1.3167e-05 - val_recall: 0.9063\n",
            "Epoch 2/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0065 - mean_io_u: 0.4993 - f1-score: 0.0245 - precision: 0.0519 - recall: 0.3246 - val_loss: 1.2436e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.8229e-06 - val_precision: 1.3055e-05 - val_recall: 0.9063\n",
            "Epoch 3/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0063 - mean_io_u: 0.4993 - f1-score: 0.0263 - precision: 0.0519 - recall: 0.3248 - val_loss: 1.1714e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.5831e-06 - val_precision: 1.1172e-05 - val_recall: 0.9063\n",
            "Epoch 4/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0064 - mean_io_u: 0.4993 - f1-score: 0.0245 - precision: 0.0524 - recall: 0.3246 - val_loss: 1.1871e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.0469e-06 - val_precision: 1.1727e-05 - val_recall: 0.9063\n",
            "Epoch 5/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0066 - mean_io_u: 0.4993 - f1-score: 0.0233 - precision: 0.0459 - recall: 0.3217 - val_loss: 1.1721e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.5064e-06 - val_precision: 1.0278e-05 - val_recall: 0.9063\n",
            "Epoch 6/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0063 - mean_io_u: 0.4993 - f1-score: 0.0248 - precision: 0.0505 - recall: 0.3240 - val_loss: 1.2809e-04 - val_mean_io_u: 0.5000 - val_f1-score: 8.6646e-06 - val_precision: 1.8522e-05 - val_recall: 0.9063\n",
            "Epoch 7/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0062 - mean_io_u: 0.4993 - f1-score: 0.0296 - precision: 0.0481 - recall: 0.3289 - val_loss: 1.1723e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.6435e-06 - val_precision: 1.1626e-05 - val_recall: 0.9063\n",
            "Epoch 8/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0063 - mean_io_u: 0.4993 - f1-score: 0.0245 - precision: 0.0497 - recall: 0.3242 - val_loss: 1.2765e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.6553e-06 - val_precision: 1.5128e-05 - val_recall: 0.9063\n",
            "Epoch 9/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0067 - mean_io_u: 0.4993 - f1-score: 0.0237 - precision: 0.0459 - recall: 0.3242 - val_loss: 1.2145e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.4491e-06 - val_precision: 1.1300e-05 - val_recall: 0.9063\n",
            "Epoch 10/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0063 - mean_io_u: 0.4993 - f1-score: 0.0249 - precision: 0.0521 - recall: 0.3251 - val_loss: 1.2681e-04 - val_mean_io_u: 0.5000 - val_f1-score: 7.0214e-06 - val_precision: 1.6190e-05 - val_recall: 0.9063\n",
            "Epoch 11/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0066 - mean_io_u: 0.4993 - f1-score: 0.0243 - precision: 0.0458 - recall: 0.3235 - val_loss: 1.1665e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.4416e-06 - val_precision: 1.0447e-05 - val_recall: 0.9063\n",
            "Epoch 12/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0063 - mean_io_u: 0.4993 - f1-score: 0.0271 - precision: 0.0511 - recall: 0.3280 - val_loss: 1.2936e-04 - val_mean_io_u: 0.5000 - val_f1-score: 9.5955e-06 - val_precision: 1.9221e-05 - val_recall: 0.9063\n",
            "Epoch 13/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0065 - mean_io_u: 0.4993 - f1-score: 0.0238 - precision: 0.0517 - recall: 0.3240 - val_loss: 1.1777e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.7615e-06 - val_precision: 1.1333e-05 - val_recall: 0.9063\n",
            "Epoch 14/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0064 - mean_io_u: 0.4993 - f1-score: 0.0242 - precision: 0.0529 - recall: 0.3247 - val_loss: 1.2173e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.2140e-06 - val_precision: 1.3206e-05 - val_recall: 0.9063\n",
            "Epoch 15/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0067 - mean_io_u: 0.4993 - f1-score: 0.0231 - precision: 0.0462 - recall: 0.3225 - val_loss: 1.1617e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.4223e-06 - val_precision: 1.0162e-05 - val_recall: 0.9063\n",
            "Epoch 16/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0063 - mean_io_u: 0.4993 - f1-score: 0.0243 - precision: 0.0532 - recall: 0.3246 - val_loss: 1.1944e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.1982e-06 - val_precision: 1.1695e-05 - val_recall: 0.9063\n",
            "Epoch 17/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0066 - mean_io_u: 0.4993 - f1-score: 0.0227 - precision: 0.0479 - recall: 0.3218 - val_loss: 1.1698e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.6161e-06 - val_precision: 9.5248e-06 - val_recall: 0.9063\n",
            "Epoch 18/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0082 - mean_io_u: 0.4993 - f1-score: 0.0258 - precision: 0.0405 - recall: 0.3230 - val_loss: 1.4253e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.8881e-06 - val_precision: 4.9075e-06 - val_recall: 0.9063\n",
            "Epoch 19/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0065 - mean_io_u: 0.4993 - f1-score: 0.0230 - precision: 0.0529 - recall: 0.3228 - val_loss: 1.1738e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.6795e-06 - val_precision: 9.8726e-06 - val_recall: 0.9063\n",
            "Epoch 20/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0064 - mean_io_u: 0.4993 - f1-score: 0.0233 - precision: 0.0528 - recall: 0.3231 - val_loss: 1.1709e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.6157e-06 - val_precision: 9.9426e-06 - val_recall: 0.9063\n",
            "Epoch 21/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0063 - mean_io_u: 0.4993 - f1-score: 0.0239 - precision: 0.0557 - recall: 0.3232 - val_loss: 1.1552e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.3132e-06 - val_precision: 1.0397e-05 - val_recall: 0.9063\n",
            "Epoch 22/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0062 - mean_io_u: 0.4993 - f1-score: 0.0238 - precision: 0.0560 - recall: 0.3229 - val_loss: 1.1584e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.3519e-06 - val_precision: 1.0854e-05 - val_recall: 0.9063\n",
            "Epoch 23/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0062 - mean_io_u: 0.4993 - f1-score: 0.0240 - precision: 0.0565 - recall: 0.3227 - val_loss: 1.1666e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.4227e-06 - val_precision: 1.0619e-05 - val_recall: 0.9063\n",
            "Epoch 24/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0062 - mean_io_u: 0.4993 - f1-score: 0.0242 - precision: 0.0546 - recall: 0.3232 - val_loss: 1.1917e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.1130e-06 - val_precision: 1.1682e-05 - val_recall: 0.9063\n",
            "Epoch 25/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0065 - mean_io_u: 0.4993 - f1-score: 0.0227 - precision: 0.0503 - recall: 0.3221 - val_loss: 1.1599e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.2135e-06 - val_precision: 9.9696e-06 - val_recall: 0.9063\n",
            "Epoch 26/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0062 - mean_io_u: 0.4993 - f1-score: 0.0243 - precision: 0.0548 - recall: 0.3231 - val_loss: 1.1765e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.0652e-06 - val_precision: 1.2786e-05 - val_recall: 0.9063\n",
            "Epoch 27/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0063 - mean_io_u: 0.4993 - f1-score: 0.0241 - precision: 0.0529 - recall: 0.3229 - val_loss: 1.1575e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.2015e-06 - val_precision: 1.0251e-05 - val_recall: 0.9063\n",
            "Epoch 28/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0062 - mean_io_u: 0.4993 - f1-score: 0.0251 - precision: 0.0554 - recall: 0.3243 - val_loss: 1.1829e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.6988e-06 - val_precision: 1.0823e-05 - val_recall: 0.9063\n",
            "Epoch 29/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0062 - mean_io_u: 0.4993 - f1-score: 0.0248 - precision: 0.0528 - recall: 0.3234 - val_loss: 1.1599e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.2604e-06 - val_precision: 1.0351e-05 - val_recall: 0.9063\n",
            "Epoch 30/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0060 - mean_io_u: 0.4993 - f1-score: 0.0261 - precision: 0.0554 - recall: 0.3249 - val_loss: 1.2113e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.7147e-06 - val_precision: 1.2101e-05 - val_recall: 0.9063\n",
            "Epoch 31/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0061 - mean_io_u: 0.4993 - f1-score: 0.0277 - precision: 0.0544 - recall: 0.3255 - val_loss: 1.1816e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.1767e-06 - val_precision: 1.1120e-05 - val_recall: 0.9063\n",
            "Epoch 32/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0060 - mean_io_u: 0.4993 - f1-score: 0.0306 - precision: 0.0548 - recall: 0.3262 - val_loss: 1.2177e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.2620e-06 - val_precision: 7.2379e-06 - val_recall: 0.9063\n",
            "Epoch 33/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0061 - mean_io_u: 0.4993 - f1-score: 0.0327 - precision: 0.0563 - recall: 0.3329 - val_loss: 1.1831e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.6476e-06 - val_precision: 1.0045e-05 - val_recall: 0.9063\n",
            "Epoch 34/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0061 - mean_io_u: 0.4993 - f1-score: 0.0312 - precision: 0.0560 - recall: 0.3315 - val_loss: 1.1639e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.4710e-06 - val_precision: 9.7656e-06 - val_recall: 0.9063\n",
            "Epoch 35/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0060 - mean_io_u: 0.4993 - f1-score: 0.0341 - precision: 0.0591 - recall: 0.3346 - val_loss: 1.1768e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.3889e-06 - val_precision: 8.8411e-06 - val_recall: 0.9063\n",
            "Epoch 36/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0058 - mean_io_u: 0.4993 - f1-score: 0.0367 - precision: 0.0647 - recall: 0.3346 - val_loss: 1.1811e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.6939e-06 - val_precision: 9.0222e-06 - val_recall: 0.9063\n",
            "Epoch 37/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0057 - mean_io_u: 0.4993 - f1-score: 0.0417 - precision: 0.0698 - recall: 0.3425 - val_loss: 1.2705e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.7495e-06 - val_precision: 6.9216e-06 - val_recall: 0.9063\n",
            "Epoch 38/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0056 - mean_io_u: 0.4993 - f1-score: 0.0409 - precision: 0.0732 - recall: 0.3390 - val_loss: 1.4651e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.7533e-06 - val_precision: 8.1563e-06 - val_recall: 0.9063\n",
            "Epoch 39/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0055 - mean_io_u: 0.4993 - f1-score: 0.0423 - precision: 0.0701 - recall: 0.3395 - val_loss: 1.2957e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.4771e-06 - val_precision: 1.0572e-05 - val_recall: 0.9063\n",
            "Epoch 40/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0054 - mean_io_u: 0.4993 - f1-score: 0.0461 - precision: 0.0736 - recall: 0.3422 - val_loss: 1.2059e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.9906e-06 - val_precision: 1.5549e-05 - val_recall: 0.9063\n",
            "Epoch 41/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0054 - mean_io_u: 0.4993 - f1-score: 0.0488 - precision: 0.0782 - recall: 0.3481 - val_loss: 1.1722e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.6564e-06 - val_precision: 9.7688e-06 - val_recall: 0.9063\n",
            "Epoch 42/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0054 - mean_io_u: 0.4993 - f1-score: 0.0466 - precision: 0.0780 - recall: 0.3435 - val_loss: 1.1723e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.5727e-06 - val_precision: 9.4975e-06 - val_recall: 0.9063\n",
            "Epoch 43/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0052 - mean_io_u: 0.4993 - f1-score: 0.0530 - precision: 0.0795 - recall: 0.3490 - val_loss: 1.2154e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.2223e-06 - val_precision: 6.5681e-06 - val_recall: 0.9063\n",
            "Epoch 44/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0051 - mean_io_u: 0.4993 - f1-score: 0.0525 - precision: 0.0815 - recall: 0.3475 - val_loss: 1.1903e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.2933e-06 - val_precision: 7.7840e-06 - val_recall: 0.9063\n",
            "Epoch 45/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0051 - mean_io_u: 0.4993 - f1-score: 0.0571 - precision: 0.0853 - recall: 0.3553 - val_loss: 1.2398e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.8744e-06 - val_precision: 5.1312e-06 - val_recall: 0.9063\n",
            "Epoch 46/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0050 - mean_io_u: 0.4993 - f1-score: 0.0581 - precision: 0.0820 - recall: 0.3533 - val_loss: 1.3558e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.4002e-06 - val_precision: 2.6932e-06 - val_recall: 0.9063\n",
            "Epoch 47/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0049 - mean_io_u: 0.4993 - f1-score: 0.0602 - precision: 0.0876 - recall: 0.3569 - val_loss: 1.4531e-04 - val_mean_io_u: 0.5000 - val_f1-score: 8.4197e-07 - val_precision: 1.3669e-06 - val_recall: 0.9063\n",
            "Epoch 48/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0047 - mean_io_u: 0.4993 - f1-score: 0.0654 - precision: 0.0934 - recall: 0.3604 - val_loss: 1.3061e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.6888e-06 - val_precision: 3.2335e-06 - val_recall: 0.9063\n",
            "Epoch 49/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0047 - mean_io_u: 0.4993 - f1-score: 0.0676 - precision: 0.0952 - recall: 0.3622 - val_loss: 1.2190e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.2248e-06 - val_precision: 1.1660e-05 - val_recall: 0.9063\n",
            "Epoch 50/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0045 - mean_io_u: 0.4993 - f1-score: 0.0749 - precision: 0.1022 - recall: 0.3711 - val_loss: 1.2611e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.7945e-06 - val_precision: 1.5588e-05 - val_recall: 0.9063\n",
            "Epoch 51/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0044 - mean_io_u: 0.4993 - f1-score: 0.0803 - precision: 0.1075 - recall: 0.3739 - val_loss: 1.2982e-04 - val_mean_io_u: 0.5000 - val_f1-score: 9.7300e-06 - val_precision: 1.8842e-05 - val_recall: 0.9063\n",
            "Epoch 52/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0044 - mean_io_u: 0.4993 - f1-score: 0.0794 - precision: 0.1079 - recall: 0.3730 - val_loss: 1.2533e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.5061e-06 - val_precision: 1.6636e-05 - val_recall: 0.9063\n",
            "Epoch 53/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0045 - mean_io_u: 0.4993 - f1-score: 0.0844 - precision: 0.1091 - recall: 0.3840 - val_loss: 1.3885e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.7480e-05 - val_precision: 3.9065e-05 - val_recall: 0.9063\n",
            "Epoch 54/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0043 - mean_io_u: 0.4993 - f1-score: 0.0924 - precision: 0.1206 - recall: 0.3898 - val_loss: 1.3018e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.0032e-05 - val_precision: 1.9134e-05 - val_recall: 0.9063\n",
            "Epoch 55/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0040 - mean_io_u: 0.4993 - f1-score: 0.1120 - precision: 0.1337 - recall: 0.4092 - val_loss: 1.2943e-04 - val_mean_io_u: 0.5000 - val_f1-score: 9.8295e-06 - val_precision: 1.9500e-05 - val_recall: 0.9063\n",
            "Epoch 56/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0040 - mean_io_u: 0.4993 - f1-score: 0.1220 - precision: 0.1455 - recall: 0.4222 - val_loss: 1.2754e-04 - val_mean_io_u: 0.5000 - val_f1-score: 8.9175e-06 - val_precision: 1.9263e-05 - val_recall: 0.9063\n",
            "Epoch 57/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0037 - mean_io_u: 0.4993 - f1-score: 0.1274 - precision: 0.1513 - recall: 0.4205 - val_loss: 1.2822e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.0032e-05 - val_precision: 2.0849e-05 - val_recall: 0.9063\n",
            "Epoch 58/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0033 - mean_io_u: 0.4993 - f1-score: 0.1521 - precision: 0.1757 - recall: 0.4479 - val_loss: 1.2556e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.0991e-06 - val_precision: 1.4797e-05 - val_recall: 0.9063\n",
            "Epoch 59/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0031 - mean_io_u: 0.4993 - f1-score: 0.1655 - precision: 0.1852 - recall: 0.4583 - val_loss: 1.2709e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.5364e-06 - val_precision: 1.2531e-05 - val_recall: 0.9063\n",
            "Epoch 60/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0029 - mean_io_u: 0.4993 - f1-score: 0.1823 - precision: 0.2036 - recall: 0.4746 - val_loss: 1.3182e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.2083e-05 - val_precision: 2.1622e-05 - val_recall: 0.9063\n",
            "Epoch 61/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0027 - mean_io_u: 0.4993 - f1-score: 0.2043 - precision: 0.2233 - recall: 0.4977 - val_loss: 1.3235e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1003e-05 - val_precision: 1.9593e-05 - val_recall: 0.9063\n",
            "Epoch 62/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0025 - mean_io_u: 0.4993 - f1-score: 0.2258 - precision: 0.2447 - recall: 0.5207 - val_loss: 1.3289e-04 - val_mean_io_u: 0.5000 - val_f1-score: 9.2748e-06 - val_precision: 1.6646e-05 - val_recall: 0.9063\n",
            "Epoch 63/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0024 - mean_io_u: 0.4993 - f1-score: 0.2415 - precision: 0.2603 - recall: 0.5343 - val_loss: 1.3130e-04 - val_mean_io_u: 0.5000 - val_f1-score: 9.4104e-06 - val_precision: 1.7966e-05 - val_recall: 0.9063\n",
            "Epoch 64/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0021 - mean_io_u: 0.4993 - f1-score: 0.2643 - precision: 0.2763 - recall: 0.5575 - val_loss: 1.3471e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.2573e-05 - val_precision: 2.1594e-05 - val_recall: 0.9063\n",
            "Epoch 65/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0020 - mean_io_u: 0.4993 - f1-score: 0.2738 - precision: 0.2866 - recall: 0.5668 - val_loss: 1.3640e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.2593e-05 - val_precision: 2.1359e-05 - val_recall: 0.9063\n",
            "Epoch 66/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0019 - mean_io_u: 0.4993 - f1-score: 0.2940 - precision: 0.3054 - recall: 0.5919 - val_loss: 1.3082e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.6715e-06 - val_precision: 1.2114e-05 - val_recall: 0.9063\n",
            "Epoch 67/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0018 - mean_io_u: 0.4993 - f1-score: 0.3023 - precision: 0.3134 - recall: 0.5981 - val_loss: 1.4033e-04 - val_mean_io_u: 0.5000 - val_f1-score: 9.8757e-06 - val_precision: 1.4975e-05 - val_recall: 0.9063\n",
            "Epoch 68/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0018 - mean_io_u: 0.4993 - f1-score: 0.3128 - precision: 0.3263 - recall: 0.6076 - val_loss: 1.3826e-04 - val_mean_io_u: 0.5000 - val_f1-score: 8.0834e-06 - val_precision: 1.3609e-05 - val_recall: 0.9063\n",
            "Epoch 69/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0017 - mean_io_u: 0.4993 - f1-score: 0.3211 - precision: 0.3345 - recall: 0.6189 - val_loss: 1.4172e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1641e-05 - val_precision: 1.7314e-05 - val_recall: 0.9063\n",
            "Epoch 70/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0017 - mean_io_u: 0.4993 - f1-score: 0.3266 - precision: 0.3375 - recall: 0.6258 - val_loss: 1.3834e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1903e-05 - val_precision: 1.9653e-05 - val_recall: 0.9063\n",
            "Epoch 71/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0017 - mean_io_u: 0.4993 - f1-score: 0.3250 - precision: 0.3409 - recall: 0.6215 - val_loss: 1.4222e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.3103e-05 - val_precision: 1.9392e-05 - val_recall: 0.9063\n",
            "Epoch 72/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0017 - mean_io_u: 0.4993 - f1-score: 0.3357 - precision: 0.3450 - recall: 0.6347 - val_loss: 1.4842e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.5257e-05 - val_precision: 3.2604e-05 - val_recall: 0.9063\n",
            "Epoch 73/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0015 - mean_io_u: 0.4993 - f1-score: 0.3496 - precision: 0.3578 - recall: 0.6497 - val_loss: 1.4672e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.7478e-05 - val_precision: 2.3918e-05 - val_recall: 0.9063\n",
            "Epoch 74/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0015 - mean_io_u: 0.4993 - f1-score: 0.3596 - precision: 0.3654 - recall: 0.6607 - val_loss: 1.4303e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1702e-05 - val_precision: 1.7074e-05 - val_recall: 0.9063\n",
            "Epoch 75/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0015 - mean_io_u: 0.4993 - f1-score: 0.3562 - precision: 0.3653 - recall: 0.6575 - val_loss: 1.4187e-04 - val_mean_io_u: 0.5000 - val_f1-score: 9.3841e-06 - val_precision: 1.3880e-05 - val_recall: 0.9063\n",
            "Epoch 76/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0016 - mean_io_u: 0.4993 - f1-score: 0.3516 - precision: 0.3653 - recall: 0.6534 - val_loss: 1.4392e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1153e-05 - val_precision: 1.6031e-05 - val_recall: 0.9063\n",
            "Epoch 77/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0015 - mean_io_u: 0.4993 - f1-score: 0.3599 - precision: 0.3676 - recall: 0.6619 - val_loss: 1.4250e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1397e-05 - val_precision: 1.6457e-05 - val_recall: 0.9063\n",
            "Epoch 78/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0016 - mean_io_u: 0.4993 - f1-score: 0.3575 - precision: 0.3698 - recall: 0.6630 - val_loss: 1.3729e-04 - val_mean_io_u: 0.5000 - val_f1-score: 7.6720e-06 - val_precision: 1.2972e-05 - val_recall: 0.9063\n",
            "Epoch 79/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0016 - mean_io_u: 0.4993 - f1-score: 0.3480 - precision: 0.3629 - recall: 0.6552 - val_loss: 1.3760e-04 - val_mean_io_u: 0.5000 - val_f1-score: 8.0340e-06 - val_precision: 1.3651e-05 - val_recall: 0.9063\n",
            "Epoch 80/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0014 - mean_io_u: 0.4993 - f1-score: 0.3701 - precision: 0.3781 - recall: 0.6742 - val_loss: 1.4460e-04 - val_mean_io_u: 0.5000 - val_f1-score: 7.5629e-06 - val_precision: 1.1177e-05 - val_recall: 0.9063\n",
            "Epoch 81/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0014 - mean_io_u: 0.4993 - f1-score: 0.3798 - precision: 0.3864 - recall: 0.6826 - val_loss: 1.4364e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.9043e-06 - val_precision: 1.0137e-05 - val_recall: 0.9063\n",
            "Epoch 82/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0013 - mean_io_u: 0.4993 - f1-score: 0.3804 - precision: 0.3882 - recall: 0.6818 - val_loss: 1.6369e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.7872e-05 - val_precision: 3.2608e-05 - val_recall: 0.9063\n",
            "Epoch 83/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0013 - mean_io_u: 0.4993 - f1-score: 0.3907 - precision: 0.3968 - recall: 0.6921 - val_loss: 1.4931e-04 - val_mean_io_u: 0.5000 - val_f1-score: 8.1963e-06 - val_precision: 1.0814e-05 - val_recall: 0.9063\n",
            "Epoch 84/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0012 - mean_io_u: 0.4993 - f1-score: 0.4001 - precision: 0.4059 - recall: 0.7013 - val_loss: 1.5453e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1796e-05 - val_precision: 1.4279e-05 - val_recall: 0.9063\n",
            "Epoch 85/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0012 - mean_io_u: 0.4993 - f1-score: 0.4008 - precision: 0.4071 - recall: 0.7007 - val_loss: 1.4996e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.7566e-05 - val_precision: 2.2204e-05 - val_recall: 0.9063\n",
            "Epoch 86/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0012 - mean_io_u: 0.4993 - f1-score: 0.4043 - precision: 0.4109 - recall: 0.7042 - val_loss: 1.5364e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.3202e-05 - val_precision: 2.7773e-05 - val_recall: 0.9063\n",
            "Epoch 87/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0012 - mean_io_u: 0.4993 - f1-score: 0.4028 - precision: 0.4089 - recall: 0.7013 - val_loss: 1.5135e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.8385e-05 - val_precision: 2.3047e-05 - val_recall: 0.9063\n",
            "Epoch 88/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0012 - mean_io_u: 0.4993 - f1-score: 0.4034 - precision: 0.4110 - recall: 0.7008 - val_loss: 1.4036e-04 - val_mean_io_u: 0.5000 - val_f1-score: 8.9515e-06 - val_precision: 1.3933e-05 - val_recall: 0.9063\n",
            "Epoch 89/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0012 - mean_io_u: 0.4993 - f1-score: 0.3917 - precision: 0.4055 - recall: 0.6892 - val_loss: 1.3870e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.9853e-06 - val_precision: 5.7732e-06 - val_recall: 0.9063\n",
            "Epoch 90/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0012 - mean_io_u: 0.4993 - f1-score: 0.4115 - precision: 0.4189 - recall: 0.7079 - val_loss: 1.5190e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.2141e-05 - val_precision: 1.5465e-05 - val_recall: 0.9063\n",
            "Epoch 91/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0011 - mean_io_u: 0.4993 - f1-score: 0.4211 - precision: 0.4259 - recall: 0.7178 - val_loss: 1.6636e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.6208e-05 - val_precision: 4.1350e-05 - val_recall: 0.9063\n",
            "Epoch 92/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0011 - mean_io_u: 0.4993 - f1-score: 0.4279 - precision: 0.4334 - recall: 0.7242 - val_loss: 1.5732e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.5076e-05 - val_precision: 1.8004e-05 - val_recall: 0.9063\n",
            "Epoch 93/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0011 - mean_io_u: 0.4993 - f1-score: 0.4285 - precision: 0.4332 - recall: 0.7232 - val_loss: 1.6375e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.2525e-05 - val_precision: 1.4231e-05 - val_recall: 0.9063\n",
            "Epoch 94/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0011 - mean_io_u: 0.4993 - f1-score: 0.4319 - precision: 0.4380 - recall: 0.7294 - val_loss: 1.4892e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.0070e-05 - val_precision: 1.2599e-05 - val_recall: 0.9063\n",
            "Epoch 95/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0011 - mean_io_u: 0.4993 - f1-score: 0.4357 - precision: 0.4400 - recall: 0.7346 - val_loss: 1.5905e-04 - val_mean_io_u: 0.5000 - val_f1-score: 9.5229e-05 - val_precision: 1.1032e-04 - val_recall: 0.9063\n",
            "Epoch 96/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0010 - mean_io_u: 0.4993 - f1-score: 0.4415 - precision: 0.4429 - recall: 0.7400 - val_loss: 1.5276e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1135e-05 - val_precision: 1.3108e-05 - val_recall: 0.9063\n",
            "Epoch 97/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0011 - mean_io_u: 0.4993 - f1-score: 0.4274 - precision: 0.4383 - recall: 0.7249 - val_loss: 1.6202e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.6964e-04 - val_precision: 1.9262e-04 - val_recall: 0.9063\n",
            "Epoch 98/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0010 - mean_io_u: 0.4993 - f1-score: 0.4368 - precision: 0.4427 - recall: 0.7356 - val_loss: 1.6127e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1176e-05 - val_precision: 1.2674e-05 - val_recall: 0.9063\n",
            "Epoch 99/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0010 - mean_io_u: 0.4993 - f1-score: 0.4394 - precision: 0.4451 - recall: 0.7389 - val_loss: 1.5980e-04 - val_mean_io_u: 0.5000 - val_f1-score: 8.1467e-06 - val_precision: 9.3354e-06 - val_recall: 0.9063\n",
            "Epoch 100/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0011 - mean_io_u: 0.4993 - f1-score: 0.4323 - precision: 0.4396 - recall: 0.7293 - val_loss: 1.4502e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.5275e-05 - val_precision: 2.0901e-05 - val_recall: 0.9063\n",
            "Epoch 101/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0010 - mean_io_u: 0.4993 - f1-score: 0.4363 - precision: 0.4450 - recall: 0.7323 - val_loss: 1.6631e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.0957e-05 - val_precision: 3.4808e-05 - val_recall: 0.9063\n",
            "Epoch 102/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0010 - mean_io_u: 0.4993 - f1-score: 0.4494 - precision: 0.4540 - recall: 0.7466 - val_loss: 1.6186e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.6613e-05 - val_precision: 7.5955e-05 - val_recall: 0.9063\n",
            "Epoch 103/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 9.6031e-04 - mean_io_u: 0.4993 - f1-score: 0.4544 - precision: 0.4608 - recall: 0.7510 - val_loss: 1.6353e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.6502e-05 - val_precision: 2.9916e-05 - val_recall: 0.9063\n",
            "Epoch 104/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 9.4759e-04 - mean_io_u: 0.4993 - f1-score: 0.4588 - precision: 0.4622 - recall: 0.7552 - val_loss: 1.7349e-04 - val_mean_io_u: 0.5000 - val_f1-score: 7.1129e-05 - val_precision: 7.9320e-05 - val_recall: 0.9063\n",
            "Epoch 105/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 9.7084e-04 - mean_io_u: 0.4993 - f1-score: 0.4554 - precision: 0.4589 - recall: 0.7543 - val_loss: 1.6418e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.5999e-05 - val_precision: 1.8126e-05 - val_recall: 0.9063\n",
            "Epoch 106/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0010 - mean_io_u: 0.4993 - f1-score: 0.4488 - precision: 0.4507 - recall: 0.7489 - val_loss: 1.6360e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.6190e-05 - val_precision: 1.8261e-05 - val_recall: 0.9063\n",
            "Epoch 107/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 9.7961e-04 - mean_io_u: 0.4993 - f1-score: 0.4530 - precision: 0.4566 - recall: 0.7520 - val_loss: 1.7265e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.4177e-04 - val_precision: 1.5789e-04 - val_recall: 0.9063\n",
            "Epoch 108/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 9.6915e-04 - mean_io_u: 0.4993 - f1-score: 0.4566 - precision: 0.4610 - recall: 0.7560 - val_loss: 1.7003e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.0296e-05 - val_precision: 3.3775e-05 - val_recall: 0.9063\n",
            "Epoch 109/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 9.7465e-04 - mean_io_u: 0.4993 - f1-score: 0.4622 - precision: 0.4621 - recall: 0.7613 - val_loss: 1.7209e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.6799e-05 - val_precision: 1.8648e-05 - val_recall: 0.9063\n",
            "Epoch 110/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 9.6394e-04 - mean_io_u: 0.4993 - f1-score: 0.4540 - precision: 0.4633 - recall: 0.7472 - val_loss: 1.6726e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.6356e-05 - val_precision: 2.9547e-05 - val_recall: 0.9063\n",
            "Epoch 111/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 9.4566e-04 - mean_io_u: 0.4993 - f1-score: 0.4603 - precision: 0.4646 - recall: 0.7573 - val_loss: 1.7045e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.7619e-05 - val_precision: 7.5699e-05 - val_recall: 0.9063\n",
            "Epoch 112/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0010 - mean_io_u: 0.4993 - f1-score: 0.4563 - precision: 0.4568 - recall: 0.7604 - val_loss: 1.7622e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.8564e-04 - val_precision: 2.0676e-04 - val_recall: 0.9063\n",
            "Epoch 113/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.0010 - mean_io_u: 0.4993 - f1-score: 0.4558 - precision: 0.4620 - recall: 0.7523 - val_loss: 1.7094e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1334e-04 - val_precision: 1.2670e-04 - val_recall: 0.9063\n",
            "Epoch 114/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 9.8554e-04 - mean_io_u: 0.4993 - f1-score: 0.4592 - precision: 0.4619 - recall: 0.7594 - val_loss: 1.7707e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.6110e-04 - val_precision: 1.7975e-04 - val_recall: 0.9063\n",
            "Epoch 115/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 9.6760e-04 - mean_io_u: 0.4993 - f1-score: 0.4608 - precision: 0.4646 - recall: 0.7613 - val_loss: 1.7482e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.3033e-05 - val_precision: 7.0475e-05 - val_recall: 0.9063\n",
            "Epoch 116/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 9.7169e-04 - mean_io_u: 0.4993 - f1-score: 0.4604 - precision: 0.4629 - recall: 0.7620 - val_loss: 1.7684e-04 - val_mean_io_u: 0.5000 - val_f1-score: 8.2707e-05 - val_precision: 9.2143e-05 - val_recall: 0.9063\n",
            "Epoch 117/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 9.2246e-04 - mean_io_u: 0.4993 - f1-score: 0.4715 - precision: 0.4782 - recall: 0.7672 - val_loss: 1.6860e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.7416e-05 - val_precision: 3.0849e-05 - val_recall: 0.9063\n",
            "Epoch 118/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 9.2123e-04 - mean_io_u: 0.4993 - f1-score: 0.4745 - precision: 0.4774 - recall: 0.7720 - val_loss: 1.6934e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.4678e-05 - val_precision: 1.6619e-05 - val_recall: 0.9063\n",
            "Epoch 119/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 9.6753e-04 - mean_io_u: 0.4993 - f1-score: 0.4599 - precision: 0.4649 - recall: 0.7592 - val_loss: 1.6860e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.4603e-05 - val_precision: 6.1732e-05 - val_recall: 0.9063\n",
            "Epoch 120/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 9.4169e-04 - mean_io_u: 0.4993 - f1-score: 0.4678 - precision: 0.4686 - recall: 0.7717 - val_loss: 1.7065e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.3627e-05 - val_precision: 3.7807e-05 - val_recall: 0.9063\n",
            "Epoch 121/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.9900e-04 - mean_io_u: 0.4993 - f1-score: 0.4728 - precision: 0.4768 - recall: 0.7708 - val_loss: 1.7342e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.0296e-05 - val_precision: 2.2704e-05 - val_recall: 0.9063\n",
            "Epoch 122/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.6825e-04 - mean_io_u: 0.4993 - f1-score: 0.4800 - precision: 0.4811 - recall: 0.7787 - val_loss: 1.7339e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.8998e-05 - val_precision: 6.6214e-05 - val_recall: 0.9063\n",
            "Epoch 123/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.6358e-04 - mean_io_u: 0.4993 - f1-score: 0.4815 - precision: 0.4850 - recall: 0.7777 - val_loss: 1.8631e-04 - val_mean_io_u: 0.5000 - val_f1-score: 7.7878e-05 - val_precision: 8.7269e-05 - val_recall: 0.9063\n",
            "Epoch 124/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.4049e-04 - mean_io_u: 0.4993 - f1-score: 0.4877 - precision: 0.4916 - recall: 0.7825 - val_loss: 1.8053e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.4597e-05 - val_precision: 6.1058e-05 - val_recall: 0.9063\n",
            "Epoch 125/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.6373e-04 - mean_io_u: 0.4993 - f1-score: 0.4847 - precision: 0.4862 - recall: 0.7830 - val_loss: 1.7498e-04 - val_mean_io_u: 0.5000 - val_f1-score: 9.5923e-05 - val_precision: 1.0766e-04 - val_recall: 0.9063\n",
            "Epoch 126/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.5428e-04 - mean_io_u: 0.4993 - f1-score: 0.4828 - precision: 0.4879 - recall: 0.7815 - val_loss: 1.9047e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.5852e-05 - val_precision: 3.9884e-05 - val_recall: 0.9063\n",
            "Epoch 127/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.7191e-04 - mean_io_u: 0.4993 - f1-score: 0.4786 - precision: 0.4840 - recall: 0.7764 - val_loss: 1.7805e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.4689e-04 - val_precision: 1.6518e-04 - val_recall: 0.9063\n",
            "Epoch 128/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.9494e-04 - mean_io_u: 0.4993 - f1-score: 0.4734 - precision: 0.4814 - recall: 0.7717 - val_loss: 1.6235e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.5937e-05 - val_precision: 5.2851e-05 - val_recall: 0.9063\n",
            "Epoch 129/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 9.4869e-04 - mean_io_u: 0.4993 - f1-score: 0.4549 - precision: 0.4644 - recall: 0.7525 - val_loss: 1.8300e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1627e-04 - val_precision: 1.3073e-04 - val_recall: 0.9063\n",
            "Epoch 130/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.7160e-04 - mean_io_u: 0.4993 - f1-score: 0.4807 - precision: 0.4865 - recall: 0.7762 - val_loss: 1.7067e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.1285e-04 - val_precision: 1.2764e-04 - val_recall: 0.9063\n",
            "Epoch 131/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.6267e-04 - mean_io_u: 0.4993 - f1-score: 0.4756 - precision: 0.4873 - recall: 0.7673 - val_loss: 2.0041e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.4473e-04 - val_precision: 6.0311e-04 - val_recall: 0.9063\n",
            "Epoch 132/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.3416e-04 - mean_io_u: 0.4993 - f1-score: 0.4825 - precision: 0.4941 - recall: 0.7747 - val_loss: 1.9968e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.0654e-04 - val_precision: 5.6113e-04 - val_recall: 0.9063\n",
            "Epoch 133/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.3154e-04 - mean_io_u: 0.4993 - f1-score: 0.4812 - precision: 0.4944 - recall: 0.7718 - val_loss: 2.0876e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.0206e-04 - val_precision: 3.3614e-04 - val_recall: 0.9063\n",
            "Epoch 134/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.4214e-04 - mean_io_u: 0.4993 - f1-score: 0.4821 - precision: 0.4913 - recall: 0.7767 - val_loss: 1.6639e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.8300e-05 - val_precision: 3.2510e-05 - val_recall: 0.9063\n",
            "Epoch 135/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 8.3808e-04 - mean_io_u: 0.4993 - f1-score: 0.4935 - precision: 0.4980 - recall: 0.7926 - val_loss: 1.8724e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.8888e-04 - val_precision: 2.1109e-04 - val_recall: 0.9063\n",
            "Epoch 136/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 8.0764e-04 - mean_io_u: 0.4993 - f1-score: 0.5005 - precision: 0.5030 - recall: 0.7975 - val_loss: 1.9685e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.0546e-04 - val_precision: 3.4003e-04 - val_recall: 0.9063\n",
            "Epoch 137/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.0345e-04 - mean_io_u: 0.4993 - f1-score: 0.4989 - precision: 0.5026 - recall: 0.7953 - val_loss: 1.7532e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.4343e-04 - val_precision: 1.6105e-04 - val_recall: 0.9063\n",
            "Epoch 138/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.0484e-04 - mean_io_u: 0.4993 - f1-score: 0.4993 - precision: 0.5003 - recall: 0.8004 - val_loss: 1.9069e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.6077e-04 - val_precision: 1.7842e-04 - val_recall: 0.9063\n",
            "Epoch 139/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.0309e-04 - mean_io_u: 0.4993 - f1-score: 0.4995 - precision: 0.5041 - recall: 0.7955 - val_loss: 1.9707e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.7502e-04 - val_precision: 1.9400e-04 - val_recall: 0.9063\n",
            "Epoch 140/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.3133e-04 - mean_io_u: 0.4993 - f1-score: 0.4879 - precision: 0.4974 - recall: 0.7852 - val_loss: 1.8038e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.2331e-04 - val_precision: 2.4976e-04 - val_recall: 0.9063\n",
            "Epoch 141/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.2056e-04 - mean_io_u: 0.4993 - f1-score: 0.4936 - precision: 0.5041 - recall: 0.7880 - val_loss: 1.9091e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.6312e-04 - val_precision: 4.0316e-04 - val_recall: 0.9063\n",
            "Epoch 142/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.2247e-04 - mean_io_u: 0.4993 - f1-score: 0.4884 - precision: 0.5008 - recall: 0.7792 - val_loss: 1.8648e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.9040e-04 - val_precision: 2.1235e-04 - val_recall: 0.9063\n",
            "Epoch 143/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.3942e-04 - mean_io_u: 0.4993 - f1-score: 0.4744 - precision: 0.5005 - recall: 0.7639 - val_loss: 2.0223e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.2933e-04 - val_precision: 5.8662e-04 - val_recall: 0.9063\n",
            "Epoch 144/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.2285e-04 - mean_io_u: 0.4993 - f1-score: 0.4794 - precision: 0.5016 - recall: 0.7660 - val_loss: 2.0413e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.9849e-04 - val_precision: 6.6384e-04 - val_recall: 0.9063\n",
            "Epoch 145/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.3426e-04 - mean_io_u: 0.4993 - f1-score: 0.4831 - precision: 0.4996 - recall: 0.7750 - val_loss: 1.9777e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.5261e-04 - val_precision: 5.0266e-04 - val_recall: 0.9063\n",
            "Epoch 146/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 8.1711e-04 - mean_io_u: 0.4993 - f1-score: 0.4821 - precision: 0.4976 - recall: 0.7711 - val_loss: 1.8586e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.0648e-04 - val_precision: 2.3006e-04 - val_recall: 0.9063\n",
            "Epoch 147/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.1169e-04 - mean_io_u: 0.4993 - f1-score: 0.4894 - precision: 0.5057 - recall: 0.7813 - val_loss: 1.9687e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.0986e-04 - val_precision: 3.4381e-04 - val_recall: 0.9063\n",
            "Epoch 148/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.9935e-04 - mean_io_u: 0.4993 - f1-score: 0.4897 - precision: 0.5085 - recall: 0.7806 - val_loss: 1.9468e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.4272e-04 - val_precision: 4.9248e-04 - val_recall: 0.9063\n",
            "Epoch 149/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.9813e-04 - mean_io_u: 0.4993 - f1-score: 0.4915 - precision: 0.5071 - recall: 0.7808 - val_loss: 1.9647e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.8981e-04 - val_precision: 5.4363e-04 - val_recall: 0.9063\n",
            "Epoch 150/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.8084e-04 - mean_io_u: 0.4993 - f1-score: 0.4969 - precision: 0.5118 - recall: 0.7884 - val_loss: 1.8487e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.8087e-04 - val_precision: 3.1346e-04 - val_recall: 0.9063\n",
            "Epoch 151/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.7293e-04 - mean_io_u: 0.4993 - f1-score: 0.4963 - precision: 0.5113 - recall: 0.7906 - val_loss: 1.9500e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.3928e-04 - val_precision: 3.7819e-04 - val_recall: 0.9063\n",
            "Epoch 152/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.8025e-04 - mean_io_u: 0.4993 - f1-score: 0.5026 - precision: 0.5119 - recall: 0.7962 - val_loss: 2.1308e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.9125e-04 - val_precision: 6.5548e-04 - val_recall: 0.9063\n",
            "Epoch 153/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.8618e-04 - mean_io_u: 0.4993 - f1-score: 0.4984 - precision: 0.5101 - recall: 0.7964 - val_loss: 2.0881e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.2288e-04 - val_precision: 5.7955e-04 - val_recall: 0.9063\n",
            "Epoch 154/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.7942e-04 - mean_io_u: 0.4993 - f1-score: 0.4985 - precision: 0.5100 - recall: 0.7974 - val_loss: 1.8096e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.5202e-04 - val_precision: 1.7258e-04 - val_recall: 0.9063\n",
            "Epoch 155/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.7207e-04 - mean_io_u: 0.4993 - f1-score: 0.5074 - precision: 0.5145 - recall: 0.8045 - val_loss: 2.0249e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.2276e-04 - val_precision: 4.6947e-04 - val_recall: 0.9063\n",
            "Epoch 156/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.9120e-04 - mean_io_u: 0.4993 - f1-score: 0.5068 - precision: 0.5140 - recall: 0.8060 - val_loss: 1.9725e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.9150e-04 - val_precision: 3.2524e-04 - val_recall: 0.9063\n",
            "Epoch 157/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 8.2474e-04 - mean_io_u: 0.4993 - f1-score: 0.4996 - precision: 0.5084 - recall: 0.8021 - val_loss: 1.8389e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.9843e-04 - val_precision: 2.2335e-04 - val_recall: 0.9063\n",
            "Epoch 158/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.8442e-04 - mean_io_u: 0.4993 - f1-score: 0.5017 - precision: 0.5102 - recall: 0.8023 - val_loss: 1.9337e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.8826e-04 - val_precision: 2.0915e-04 - val_recall: 0.9063\n",
            "Epoch 159/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.5376e-04 - mean_io_u: 0.4993 - f1-score: 0.5105 - precision: 0.5136 - recall: 0.8088 - val_loss: 2.1122e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.5885e-04 - val_precision: 5.0841e-04 - val_recall: 0.9063\n",
            "Epoch 160/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.5288e-04 - mean_io_u: 0.4993 - f1-score: 0.5177 - precision: 0.5191 - recall: 0.8171 - val_loss: 2.1029e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.5797e-04 - val_precision: 7.3026e-04 - val_recall: 0.9063\n",
            "Epoch 161/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.4712e-04 - mean_io_u: 0.4993 - f1-score: 0.5187 - precision: 0.5227 - recall: 0.8166 - val_loss: 1.9707e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.5596e-04 - val_precision: 3.9912e-04 - val_recall: 0.9063\n",
            "Epoch 162/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.5736e-04 - mean_io_u: 0.4993 - f1-score: 0.5127 - precision: 0.5149 - recall: 0.8121 - val_loss: 2.1016e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.8287e-04 - val_precision: 4.2445e-04 - val_recall: 0.9063\n",
            "Epoch 163/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.3883e-04 - mean_io_u: 0.4993 - f1-score: 0.5173 - precision: 0.5218 - recall: 0.8145 - val_loss: 1.9985e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.9811e-04 - val_precision: 4.4226e-04 - val_recall: 0.9063\n",
            "Epoch 164/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.1479e-04 - mean_io_u: 0.4993 - f1-score: 0.5193 - precision: 0.5239 - recall: 0.8160 - val_loss: 2.0964e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.1242e-04 - val_precision: 4.5687e-04 - val_recall: 0.9063\n",
            "Epoch 165/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.0371e-04 - mean_io_u: 0.4993 - f1-score: 0.5201 - precision: 0.5309 - recall: 0.8128 - val_loss: 2.1311e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.8474e-04 - val_precision: 5.3754e-04 - val_recall: 0.9063\n",
            "Epoch 166/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.1490e-04 - mean_io_u: 0.4993 - f1-score: 0.5163 - precision: 0.5284 - recall: 0.8101 - val_loss: 1.9390e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.2547e-04 - val_precision: 2.5245e-04 - val_recall: 0.9063\n",
            "Epoch 167/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.2504e-04 - mean_io_u: 0.4993 - f1-score: 0.5204 - precision: 0.5278 - recall: 0.8173 - val_loss: 2.0034e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.2843e-04 - val_precision: 5.8789e-04 - val_recall: 0.9063\n",
            "Epoch 168/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 7.3448e-04 - mean_io_u: 0.4993 - f1-score: 0.5165 - precision: 0.5254 - recall: 0.8110 - val_loss: 2.1571e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.0854e-04 - val_precision: 6.7363e-04 - val_recall: 0.9063\n",
            "Epoch 169/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.5683e-04 - mean_io_u: 0.4993 - f1-score: 0.5140 - precision: 0.5225 - recall: 0.8098 - val_loss: 2.1515e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.6374e-04 - val_precision: 6.2426e-04 - val_recall: 0.9063\n",
            "Epoch 170/200\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 7.6791e-04 - mean_io_u: 0.4993 - f1-score: 0.5050 - precision: 0.5182 - recall: 0.7979 - val_loss: 2.2982e-04 - val_mean_io_u: 0.5000 - val_f1-score: 0.0011 - val_precision: 0.0013 - val_recall: 0.9063\n",
            "Epoch 171/200\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 7.4705e-04 - mean_io_u: 0.4993 - f1-score: 0.5082 - precision: 0.5177 - recall: 0.8010 - val_loss: 2.0465e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.1015e-04 - val_precision: 3.4682e-04 - val_recall: 0.9063\n",
            "Epoch 172/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.4376e-04 - mean_io_u: 0.4993 - f1-score: 0.5111 - precision: 0.5213 - recall: 0.8044 - val_loss: 2.0472e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.0448e-04 - val_precision: 6.7051e-04 - val_recall: 0.9063\n",
            "Epoch 173/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.1570e-04 - mean_io_u: 0.4993 - f1-score: 0.5200 - precision: 0.5256 - recall: 0.8165 - val_loss: 1.9475e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.6680e-04 - val_precision: 1.8571e-04 - val_recall: 0.9063\n",
            "Epoch 174/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.0606e-04 - mean_io_u: 0.4993 - f1-score: 0.5183 - precision: 0.5225 - recall: 0.8152 - val_loss: 2.1750e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.8896e-04 - val_precision: 6.5102e-04 - val_recall: 0.9063\n",
            "Epoch 175/200\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 7.1943e-04 - mean_io_u: 0.4993 - f1-score: 0.5158 - precision: 0.5261 - recall: 0.8084 - val_loss: 2.3452e-04 - val_mean_io_u: 0.5000 - val_f1-score: 0.0012 - val_precision: 0.0013 - val_recall: 0.9063\n",
            "Epoch 176/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.1651e-04 - mean_io_u: 0.4993 - f1-score: 0.5150 - precision: 0.5252 - recall: 0.8072 - val_loss: 2.2644e-04 - val_mean_io_u: 0.5000 - val_f1-score: 7.8457e-04 - val_precision: 8.6738e-04 - val_recall: 0.9063\n",
            "Epoch 177/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.2739e-04 - mean_io_u: 0.4993 - f1-score: 0.5207 - precision: 0.5292 - recall: 0.8128 - val_loss: 2.1589e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.4769e-04 - val_precision: 6.0820e-04 - val_recall: 0.9063\n",
            "Epoch 178/200\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 7.2455e-04 - mean_io_u: 0.4993 - f1-score: 0.5125 - precision: 0.5268 - recall: 0.8067 - val_loss: 2.3268e-04 - val_mean_io_u: 0.5000 - val_f1-score: 0.0029 - val_precision: 0.0032 - val_recall: 0.9063\n",
            "Epoch 179/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.1048e-04 - mean_io_u: 0.4993 - f1-score: 0.5220 - precision: 0.5260 - recall: 0.8228 - val_loss: 2.4304e-04 - val_mean_io_u: 0.5000 - val_f1-score: 0.0012 - val_precision: 0.0013 - val_recall: 0.9063\n",
            "Epoch 180/200\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 6.9272e-04 - mean_io_u: 0.4993 - f1-score: 0.5253 - precision: 0.5312 - recall: 0.8226 - val_loss: 2.2515e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.3192e-04 - val_precision: 6.9859e-04 - val_recall: 0.9063\n",
            "Epoch 181/200\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 7.2663e-04 - mean_io_u: 0.4993 - f1-score: 0.5193 - precision: 0.5285 - recall: 0.8174 - val_loss: 1.9858e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.8507e-04 - val_precision: 4.3796e-04 - val_recall: 0.9063\n",
            "Epoch 182/200\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 7.3263e-04 - mean_io_u: 0.4993 - f1-score: 0.5191 - precision: 0.5259 - recall: 0.8210 - val_loss: 2.9715e-04 - val_mean_io_u: 0.5000 - val_f1-score: 0.0112 - val_precision: 0.0123 - val_recall: 0.9063\n",
            "Epoch 183/200\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 7.9676e-04 - mean_io_u: 0.4993 - f1-score: 0.5169 - precision: 0.5236 - recall: 0.8191 - val_loss: 2.2238e-04 - val_mean_io_u: 0.5000 - val_f1-score: 0.0012 - val_precision: 0.0014 - val_recall: 0.9063\n",
            "Epoch 184/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.0013 - mean_io_u: 0.4993 - f1-score: 0.4435 - precision: 0.4679 - recall: 0.7411 - val_loss: 1.9830e-04 - val_mean_io_u: 0.5000 - val_f1-score: 0.0012 - val_precision: 0.0013 - val_recall: 0.9063\n",
            "Epoch 185/200\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 8.8144e-04 - mean_io_u: 0.4993 - f1-score: 0.4910 - precision: 0.4917 - recall: 0.7938 - val_loss: 1.7043e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.6408e-05 - val_precision: 6.6564e-05 - val_recall: 0.9063\n",
            "Epoch 186/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.7156e-04 - mean_io_u: 0.4993 - f1-score: 0.5121 - precision: 0.5130 - recall: 0.8119 - val_loss: 1.7133e-04 - val_mean_io_u: 0.5000 - val_f1-score: 7.4567e-05 - val_precision: 8.5651e-05 - val_recall: 0.9063\n",
            "Epoch 187/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.1758e-04 - mean_io_u: 0.4993 - f1-score: 0.5238 - precision: 0.5264 - recall: 0.8220 - val_loss: 1.5898e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.6168e-05 - val_precision: 6.6249e-05 - val_recall: 0.9063\n",
            "Epoch 188/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 6.9563e-04 - mean_io_u: 0.4993 - f1-score: 0.5260 - precision: 0.5282 - recall: 0.8262 - val_loss: 1.6319e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.3433e-05 - val_precision: 5.0217e-05 - val_recall: 0.9063\n",
            "Epoch 189/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 6.8238e-04 - mean_io_u: 0.4993 - f1-score: 0.5291 - precision: 0.5337 - recall: 0.8281 - val_loss: 1.6607e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.1664e-05 - val_precision: 5.8981e-05 - val_recall: 0.9063\n",
            "Epoch 190/200\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 6.7230e-04 - mean_io_u: 0.4993 - f1-score: 0.5299 - precision: 0.5364 - recall: 0.8287 - val_loss: 1.6385e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.7967e-05 - val_precision: 6.6880e-05 - val_recall: 0.9063\n",
            "Epoch 191/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 6.7068e-04 - mean_io_u: 0.4993 - f1-score: 0.5323 - precision: 0.5376 - recall: 0.8295 - val_loss: 1.6610e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.9857e-05 - val_precision: 4.5746e-05 - val_recall: 0.9063\n",
            "Epoch 192/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 6.6532e-04 - mean_io_u: 0.4993 - f1-score: 0.5296 - precision: 0.5371 - recall: 0.8250 - val_loss: 1.6753e-04 - val_mean_io_u: 0.5000 - val_f1-score: 6.4116e-05 - val_precision: 7.3240e-05 - val_recall: 0.9063\n",
            "Epoch 193/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 6.6185e-04 - mean_io_u: 0.4993 - f1-score: 0.5328 - precision: 0.5400 - recall: 0.8306 - val_loss: 1.6741e-04 - val_mean_io_u: 0.5000 - val_f1-score: 7.9719e-05 - val_precision: 9.3573e-05 - val_recall: 0.9063\n",
            "Epoch 194/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 6.7061e-04 - mean_io_u: 0.4993 - f1-score: 0.5308 - precision: 0.5368 - recall: 0.8249 - val_loss: 1.7838e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.0551e-04 - val_precision: 1.1864e-04 - val_recall: 0.9063\n",
            "Epoch 195/200\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 6.6871e-04 - mean_io_u: 0.4993 - f1-score: 0.5305 - precision: 0.5397 - recall: 0.8212 - val_loss: 1.7005e-04 - val_mean_io_u: 0.5000 - val_f1-score: 1.0482e-04 - val_precision: 1.2196e-04 - val_recall: 0.9063\n",
            "Epoch 196/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 6.7585e-04 - mean_io_u: 0.4993 - f1-score: 0.5291 - precision: 0.5394 - recall: 0.8205 - val_loss: 1.8933e-04 - val_mean_io_u: 0.5000 - val_f1-score: 2.8434e-04 - val_precision: 3.1983e-04 - val_recall: 0.9063\n",
            "Epoch 197/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 6.8231e-04 - mean_io_u: 0.4993 - f1-score: 0.5285 - precision: 0.5387 - recall: 0.8209 - val_loss: 1.9349e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.7678e-04 - val_precision: 6.4547e-04 - val_recall: 0.9063\n",
            "Epoch 198/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 6.8865e-04 - mean_io_u: 0.4993 - f1-score: 0.5308 - precision: 0.5382 - recall: 0.8275 - val_loss: 1.8787e-04 - val_mean_io_u: 0.5000 - val_f1-score: 4.7285e-04 - val_precision: 5.3055e-04 - val_recall: 0.9063\n",
            "Epoch 199/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.0511e-04 - mean_io_u: 0.4993 - f1-score: 0.5214 - precision: 0.5358 - recall: 0.8235 - val_loss: 1.7836e-04 - val_mean_io_u: 0.5000 - val_f1-score: 5.1993e-05 - val_precision: 6.0036e-05 - val_recall: 0.9063\n",
            "Epoch 200/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 7.1208e-04 - mean_io_u: 0.4993 - f1-score: 0.5223 - precision: 0.5340 - recall: 0.8243 - val_loss: 1.5129e-04 - val_mean_io_u: 0.5000 - val_f1-score: 3.8147e-05 - val_precision: 5.0047e-05 - val_recall: 0.9063\n"
          ]
        }
      ],
      "source": [
        "#Si uso el custom datagen\n",
        "steps_per_epoch = len(train_img_list)//batch_size\n",
        "val_steps_per_epoch = len(val_img_list)//batch_size\n",
        "\n",
        "history=model.fit(train_img_datagen,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=200,\n",
        "          verbose=1,\n",
        "          validation_data=val_img_datagen,\n",
        "          validation_steps=val_steps_per_epoch,\n",
        "          )\n",
        "\n",
        "model.save('modelo_1.2.hdf5')"
      ]
    }
  ]
}