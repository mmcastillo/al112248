{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMf4r/5oPpIGy3E0HxcFu8R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmcastillo/al112248/blob/main/modelo1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he1raG8TN9jT",
        "outputId": "bb7cd644-302e-4a9e-ece1-87f35dd4d049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (5.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install natsort"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/');\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate\n",
        "from scipy import ndimage\n",
        "import random\n",
        "import natsort\n",
        "import glob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRIWbDUTQFTZ",
        "outputId": "43f3b5e7-a361-4255-9ea7-489c252dfc8f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/train/50p_rand_50n/imgs/';\n",
        "train_mask_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/train/50p_rand_50n/masks/';\n",
        "\n",
        "train_img_list_temp = os.listdir(train_img_dir)\n",
        "#train_img_list = natsort.natsorted(train_img_list)\n",
        "train_mask_list_temp = os.listdir(train_mask_dir)\n",
        "#train_mask_list = natsort.natsorted(train_mask_list)\n",
        "\n",
        "#Se aleatoriza la lista del conjunto de entrenamiento\n",
        "train_img_list=[]\n",
        "train_mask_list=[]\n",
        "inx = random.sample(range(len(train_img_list_temp)), len(train_img_list_temp))  \n",
        "for i in range(len(inx)):\n",
        "  train_img_list.append(train_img_list_temp[inx[i]])\n",
        "  train_mask_list.append(train_mask_list_temp[inx[i]])\n",
        "\n",
        "val_img_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/val/imgs/';\n",
        "val_mask_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/val/masks/';\n",
        "val_img_list = os.listdir(val_img_dir)\n",
        "val_img_list = natsort.natsorted(val_img_list)\n",
        "val_mask_list = os.listdir(val_mask_dir)\n",
        "val_mask_list = natsort.natsorted(val_mask_list)"
      ],
      "metadata": {
        "id": "MruxLoBYQqFh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(img_dir, img_list):\n",
        "    images=[]\n",
        "    for i, image_name in enumerate(img_list):    \n",
        "        if (image_name.split('.')[1] == 'npy'):\n",
        "            \n",
        "            image = np.load(img_dir+image_name)\n",
        "                      \n",
        "            images.append(image)\n",
        "    images = np.array(images)\n",
        "    \n",
        "    return(images)"
      ],
      "metadata": {
        "id": "bTAaIf_5QPqC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "U8qqs4WJwYwE"
      },
      "outputs": [],
      "source": [
        "def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n",
        "\n",
        "    L = len(img_list)\n",
        "\n",
        "    #keras needs the generator infinite, so we will use while true  \n",
        "    while True:\n",
        "\n",
        "        batch_start = 0\n",
        "        batch_end = batch_size\n",
        "\n",
        "        while batch_start < L:\n",
        "            limit = min(batch_end, L)\n",
        "                       \n",
        "            X = load_img(img_dir, img_list[batch_start:limit])\n",
        "            Y = load_img(mask_dir, mask_list[batch_start:limit])\n",
        "\n",
        "            X = X.astype(np.float32)  \n",
        "            Y = Y.astype(np.float32)\n",
        "\n",
        "            #I = img_list[batch_start:limit]\n",
        "            #M = mask_list[batch_start:limit]\n",
        "\n",
        "\n",
        "            yield (X,Y)#,I,M) #a tuple with two numpy arrays with batch_size samples\n",
        "           \n",
        "            batch_start += batch_size   \n",
        "            batch_end += batch_size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "\n",
        "train_img_datagen = imageLoader(train_img_dir, train_img_list, \n",
        "                                train_mask_dir, train_mask_list,batch_size)\n",
        "\n",
        "val_img_datagen = imageLoader(val_img_dir, val_img_list, \n",
        "                                val_mask_dir, val_mask_list,batch_size)\n"
      ],
      "metadata": {
        "id": "gwccjU68Qr7L"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img,mask = train_img_datagen.__next__()\n",
        "print(img.shape)\n",
        "print(mask.shape)\n",
        "print(np.unique(mask))\n",
        "\n",
        "#Encuentra los patches 3D donde las máscaras contienen valores 1 y 0 (donde hay aneurisams)\n",
        "#if np.unique(mask).shape[0]  == 2:\n",
        "  #for i in range(mask.shape[0]):\n",
        "    #if np.unique(mask[i,:,:,:]).shape[0] == 2: \n",
        "      #n_patch_aneurisma = i\n",
        "      #print(f'En el patch número {n_patch_aneurisma+1} se encuentra el aneurisma')\n",
        "      #n_imagenes_aneurismas=[]\n",
        "      #for j in range(mask.shape[1]):\n",
        "        #if np.unique(mask[n_patch_aneurisma,j,:,:]).shape[0] == 2:\n",
        "          #print(f'En las imagenes {j+1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KHHIyA0zdAl",
        "outputId": "88cf4678-0a43-4b71-b1c3-aecd1ac49c01"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 64, 64, 64, 1)\n",
            "(4, 64, 64, 64, 1)\n",
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bv3JM39CV_tU"
      },
      "outputs": [],
      "source": [
        "def conv_block(input, num_filters):\n",
        "    x = Conv3D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)   #Not in the original network. \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv3D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)  #Not in the original network\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#Encoder block: Conv block followed by maxpooling\n",
        "\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPooling3D((2, 2, 2))(x)\n",
        "    return x, p   \n",
        "\n",
        "#Decoder block\n",
        "#skip features gets input from encoder for concatenation\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "#Build Unet using the blocks\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 16)\n",
        "    s2, p2 = encoder_block(p1, 32)\n",
        "    s3, p3 = encoder_block(p2, 64)\n",
        "    s4, p4 = encoder_block(p3, 128)\n",
        "\n",
        "    b1 = conv_block(p4, 256) #Bridge\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 128)\n",
        "    d2 = decoder_block(d1, s3, 64)\n",
        "    d3 = decoder_block(d2, s2, 32)\n",
        "    d4 = decoder_block(d3, s1, 16)\n",
        "\n",
        "    activation = 'sigmoid'\n",
        "\n",
        "    outputs = Conv3D(1, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n",
        "    print(f'activation function: {activation}')\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6qkE9MIgBYB",
        "outputId": "d8df6d14-1815-414f-f056-521d464d9406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activation function: sigmoid\n",
            "model input shape: (None, 64, 64, 64, 1)\n"
          ]
        }
      ],
      "source": [
        "model = build_unet((64, 64, 64, 1))\n",
        "print(f'model input shape: {model.input_shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ant9LozBclBY",
        "outputId": "6fd9cdec-3e25-438d-d97b-c98638840487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: segmentation-models-3D in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-3D) (2.9.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-3D) (1.0.8)\n",
            "Requirement already satisfied: classification-models-3D>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-3D) (1.0.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->segmentation-models-3D) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->segmentation-models-3D) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (21.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (3.3.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (14.0.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.50.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.27.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (4.1.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.1.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.12)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->segmentation-models-3D) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->segmentation-models-3D) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow>=2.8.0->segmentation-models-3D) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation-models-3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4-ffnnX2lDT3"
      },
      "outputs": [],
      "source": [
        "from segmentation_models_3D.losses import BinaryCELoss\n",
        "import segmentation_models_3D as sm\n",
        "from keras import backend as K\n",
        "\n",
        "'''\n",
        "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
        "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
        "'''\n",
        "dice_loss = sm.losses.DiceLoss()\n",
        "focal_loss = sm.losses.BinaryFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
        "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
        "\n",
        "iou = tf.keras.metrics.MeanIoU(num_classes=2)\n",
        "\n",
        "metrics = [iou, sm.metrics.FScore(), sm.metrics.Precision(), sm.metrics.Recall()]\n",
        "#jaccard_loss = sm.losses.JaccardLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg8cd8WeixXu",
        "outputId": "791c0f51-1508-4892-d3f5-ec4bd21aaf93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 64, 64, 64,  0           []                               \n",
            "                                 1)]                                                              \n",
            "                                                                                                  \n",
            " conv3d_19 (Conv3D)             (None, 64, 64, 64,   448         ['input_2[0][0]']                \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 64, 64, 64,   64         ['conv3d_19[0][0]']              \n",
            " ormalization)                  16)                                                               \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_18[0][0]'] \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_20 (Conv3D)             (None, 64, 64, 64,   6928        ['activation_18[0][0]']          \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 64, 64, 64,   64         ['conv3d_20[0][0]']              \n",
            " ormalization)                  16)                                                               \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_19[0][0]'] \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " max_pooling3d_4 (MaxPooling3D)  (None, 32, 32, 32,   0          ['activation_19[0][0]']          \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_21 (Conv3D)             (None, 32, 32, 32,   13856       ['max_pooling3d_4[0][0]']        \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 32, 32, 32,   128        ['conv3d_21[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_20[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_22 (Conv3D)             (None, 32, 32, 32,   27680       ['activation_20[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 32, 32, 32,   128        ['conv3d_22[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_21[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " max_pooling3d_5 (MaxPooling3D)  (None, 16, 16, 16,   0          ['activation_21[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_23 (Conv3D)             (None, 16, 16, 16,   55360       ['max_pooling3d_5[0][0]']        \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 16,   256        ['conv3d_23[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 16,   0           ['batch_normalization_22[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv3d_24 (Conv3D)             (None, 16, 16, 16,   110656      ['activation_22[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 16,   256        ['conv3d_24[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 16,   0           ['batch_normalization_23[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " max_pooling3d_6 (MaxPooling3D)  (None, 8, 8, 8, 64)  0          ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv3d_25 (Conv3D)             (None, 8, 8, 8, 128  221312      ['max_pooling3d_6[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 8, 8, 8, 128  512        ['conv3d_25[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 8, 8, 8, 128  0           ['batch_normalization_24[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_26 (Conv3D)             (None, 8, 8, 8, 128  442496      ['activation_24[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 8, 8, 8, 128  512        ['conv3d_26[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 8, 8, 8, 128  0           ['batch_normalization_25[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling3d_7 (MaxPooling3D)  (None, 4, 4, 4, 128  0          ['activation_25[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_27 (Conv3D)             (None, 4, 4, 4, 256  884992      ['max_pooling3d_7[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 4, 4, 4, 256  1024       ['conv3d_27[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 4, 4, 4, 256  0           ['batch_normalization_26[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_28 (Conv3D)             (None, 4, 4, 4, 256  1769728     ['activation_26[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 4, 4, 4, 256  1024       ['conv3d_28[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 4, 4, 4, 256  0           ['batch_normalization_27[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_transpose_4 (Conv3DTran  (None, 8, 8, 8, 128  262272     ['activation_27[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 8, 8, 8, 256  0           ['conv3d_transpose_4[0][0]',     \n",
            "                                )                                 'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv3d_29 (Conv3D)             (None, 8, 8, 8, 128  884864      ['concatenate_4[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 8, 8, 8, 128  512        ['conv3d_29[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 8, 8, 8, 128  0           ['batch_normalization_28[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_30 (Conv3D)             (None, 8, 8, 8, 128  442496      ['activation_28[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 8, 8, 8, 128  512        ['conv3d_30[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 8, 8, 8, 128  0           ['batch_normalization_29[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_transpose_5 (Conv3DTran  (None, 16, 16, 16,   65600      ['activation_29[0][0]']          \n",
            " spose)                         64)                                                               \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 16, 16, 16,   0           ['conv3d_transpose_5[0][0]',     \n",
            "                                128)                              'activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv3d_31 (Conv3D)             (None, 16, 16, 16,   221248      ['concatenate_5[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 16, 16, 16,   256        ['conv3d_31[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 16, 16, 16,   0           ['batch_normalization_30[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv3d_32 (Conv3D)             (None, 16, 16, 16,   110656      ['activation_30[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 16, 16, 16,   256        ['conv3d_32[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 16, 16, 16,   0           ['batch_normalization_31[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv3d_transpose_6 (Conv3DTran  (None, 32, 32, 32,   16416      ['activation_31[0][0]']          \n",
            " spose)                         32)                                                               \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 32, 32, 32,   0           ['conv3d_transpose_6[0][0]',     \n",
            "                                64)                               'activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " conv3d_33 (Conv3D)             (None, 32, 32, 32,   55328       ['concatenate_6[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 32, 32, 32,   128        ['conv3d_33[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_32[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_34 (Conv3D)             (None, 32, 32, 32,   27680       ['activation_32[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 32, 32, 32,   128        ['conv3d_34[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_33[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_transpose_7 (Conv3DTran  (None, 64, 64, 64,   4112       ['activation_33[0][0]']          \n",
            " spose)                         16)                                                               \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 64, 64, 64,   0           ['conv3d_transpose_7[0][0]',     \n",
            "                                32)                               'activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " conv3d_35 (Conv3D)             (None, 64, 64, 64,   13840       ['concatenate_7[0][0]']          \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 64, 64, 64,   64         ['conv3d_35[0][0]']              \n",
            " ormalization)                  16)                                                               \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_34[0][0]'] \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_36 (Conv3D)             (None, 64, 64, 64,   6928        ['activation_34[0][0]']          \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 64, 64, 64,   64         ['conv3d_36[0][0]']              \n",
            " ormalization)                  16)                                                               \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_35[0][0]'] \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_37 (Conv3D)             (None, 64, 64, 64,   17          ['activation_35[0][0]']          \n",
            "                                1)                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,650,801\n",
            "Trainable params: 5,647,857\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "LR = 0.001\n",
            "<segmentation_models_3D.base.objects.SumOfLosses object at 0x7faa7702a390>\n"
          ]
        }
      ],
      "source": [
        "LR = 0.001\n",
        "optim = keras.optimizers.Adam(LR)\n",
        "\n",
        "loss = total_loss\n",
        "\n",
        "model.compile(optimizer=optim, loss=loss ,metrics = metrics)\n",
        "print(model.summary())\n",
        "print(f'LR = {LR}')\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5n_rIbVlQ5I",
        "outputId": "9786289c-0116-4ada-b210-52b1d4e6126e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "225/225 [==============================] - 21s 78ms/step - loss: 1.0188 - mean_io_u_2: 0.4993 - f1-score: 0.0041 - precision: 0.0020 - recall: 0.4015 - val_loss: 1.0049 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.8032e-05 - val_precision: 9.0248e-06 - val_recall: 0.9239\n",
            "Epoch 2/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9958 - mean_io_u_2: 0.4993 - f1-score: 0.0082 - precision: 0.0042 - recall: 0.4132 - val_loss: 1.0002 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.8037e-05 - val_precision: 9.0425e-06 - val_recall: 0.9129\n",
            "Epoch 3/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9811 - mean_io_u_2: 0.4993 - f1-score: 0.0224 - precision: 0.0119 - recall: 0.4392 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.5269e-05 - val_precision: 7.7761e-06 - val_recall: 0.9073\n",
            "Epoch 4/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.9082 - mean_io_u_2: 0.5003 - f1-score: 0.0964 - precision: 0.0710 - recall: 0.3357 - val_loss: 1.0001 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.2762e-05 - val_precision: 1.1451e-05 - val_recall: 0.9082\n",
            "Epoch 5/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.8053 - mean_io_u_2: 0.5004 - f1-score: 0.1999 - precision: 0.1957 - recall: 0.3570 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 7.2049e-06 - val_precision: 8.2152e-06 - val_recall: 0.9063\n",
            "Epoch 6/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.7583 - mean_io_u_2: 0.5003 - f1-score: 0.2457 - precision: 0.2525 - recall: 0.3664 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 4.2392e-06 - val_precision: 8.6726e-06 - val_recall: 0.9063\n",
            "Epoch 7/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.7431 - mean_io_u_2: 0.5001 - f1-score: 0.2610 - precision: 0.2808 - recall: 0.3687 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.1604e-06 - val_precision: 8.0784e-06 - val_recall: 0.9063\n",
            "Epoch 8/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.7195 - mean_io_u_2: 0.5010 - f1-score: 0.2848 - precision: 0.3008 - recall: 0.3977 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.0378e-06 - val_precision: 9.4536e-06 - val_recall: 0.9063\n",
            "Epoch 9/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.7050 - mean_io_u_2: 0.5021 - f1-score: 0.2990 - precision: 0.3241 - recall: 0.4093 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.9725e-06 - val_precision: 9.9050e-06 - val_recall: 0.9063\n",
            "Epoch 10/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.7033 - mean_io_u_2: 0.5017 - f1-score: 0.3010 - precision: 0.3270 - recall: 0.4076 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.2383e-06 - val_precision: 1.1741e-05 - val_recall: 0.9063\n",
            "Epoch 11/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.7007 - mean_io_u_2: 0.5029 - f1-score: 0.3036 - precision: 0.3299 - recall: 0.4064 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.9390e-06 - val_precision: 1.2555e-05 - val_recall: 0.9063\n",
            "Epoch 12/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.6992 - mean_io_u_2: 0.5022 - f1-score: 0.3050 - precision: 0.3344 - recall: 0.3999 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.6216e-06 - val_precision: 1.4438e-05 - val_recall: 0.9063\n",
            "Epoch 13/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.7028 - mean_io_u_2: 0.5067 - f1-score: 0.3018 - precision: 0.3334 - recall: 0.3942 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.8999e-06 - val_precision: 1.3732e-05 - val_recall: 0.9063\n",
            "Epoch 14/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.6885 - mean_io_u_2: 0.5104 - f1-score: 0.3163 - precision: 0.3517 - recall: 0.4097 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 5.1047e-06 - val_precision: 1.8439e-05 - val_recall: 0.9063\n",
            "Epoch 15/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.6727 - mean_io_u_2: 0.5039 - f1-score: 0.3319 - precision: 0.3644 - recall: 0.4483 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.5109e-06 - val_precision: 1.5105e-05 - val_recall: 0.9063\n",
            "Epoch 16/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.6485 - mean_io_u_2: 0.5123 - f1-score: 0.3558 - precision: 0.4024 - recall: 0.4531 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 4.9928e-06 - val_precision: 1.6702e-05 - val_recall: 0.9063\n",
            "Epoch 17/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.6319 - mean_io_u_2: 0.5168 - f1-score: 0.3725 - precision: 0.4145 - recall: 0.4765 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.7914e-06 - val_precision: 1.6644e-05 - val_recall: 0.9063\n",
            "Epoch 18/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.6276 - mean_io_u_2: 0.5127 - f1-score: 0.3768 - precision: 0.4162 - recall: 0.4737 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 4.5068e-06 - val_precision: 1.7756e-05 - val_recall: 0.9063\n",
            "Epoch 19/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.6214 - mean_io_u_2: 0.5147 - f1-score: 0.3828 - precision: 0.4305 - recall: 0.4719 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 5.1101e-06 - val_precision: 2.1498e-05 - val_recall: 0.9063\n",
            "Epoch 20/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.6023 - mean_io_u_2: 0.5189 - f1-score: 0.4018 - precision: 0.4446 - recall: 0.4963 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.4262e-05 - val_precision: 3.4796e-05 - val_recall: 0.9063\n",
            "Epoch 21/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5945 - mean_io_u_2: 0.5161 - f1-score: 0.4094 - precision: 0.4601 - recall: 0.5002 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 6.3878e-06 - val_precision: 1.8412e-05 - val_recall: 0.9063\n",
            "Epoch 22/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.6012 - mean_io_u_2: 0.5090 - f1-score: 0.4029 - precision: 0.4529 - recall: 0.4919 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.3850e-05 - val_precision: 4.3892e-05 - val_recall: 0.9063\n",
            "Epoch 23/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5992 - mean_io_u_2: 0.5089 - f1-score: 0.4043 - precision: 0.4668 - recall: 0.4734 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.4297e-05 - val_precision: 4.4288e-05 - val_recall: 0.9063\n",
            "Epoch 24/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.6249 - mean_io_u_2: 0.5084 - f1-score: 0.3800 - precision: 0.4260 - recall: 0.4802 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.6807e-05 - val_precision: 3.1868e-05 - val_recall: 0.9063\n",
            "Epoch 25/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5827 - mean_io_u_2: 0.5069 - f1-score: 0.4210 - precision: 0.4712 - recall: 0.5013 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.8901e-05 - val_precision: 3.3513e-05 - val_recall: 0.9063\n",
            "Epoch 26/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5871 - mean_io_u_2: 0.5080 - f1-score: 0.4171 - precision: 0.4634 - recall: 0.5075 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 7.9911e-06 - val_precision: 2.5037e-05 - val_recall: 0.9063\n",
            "Epoch 27/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.5949 - mean_io_u_2: 0.5080 - f1-score: 0.4095 - precision: 0.4625 - recall: 0.5007 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.9125e-05 - val_precision: 5.5804e-05 - val_recall: 0.9063\n",
            "Epoch 28/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5858 - mean_io_u_2: 0.5034 - f1-score: 0.4183 - precision: 0.4742 - recall: 0.5083 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.4281e-05 - val_precision: 4.1037e-05 - val_recall: 0.9063\n",
            "Epoch 29/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5642 - mean_io_u_2: 0.5087 - f1-score: 0.4397 - precision: 0.4939 - recall: 0.5241 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 5.7991e-05 - val_precision: 7.7591e-05 - val_recall: 0.9063\n",
            "Epoch 30/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5687 - mean_io_u_2: 0.5097 - f1-score: 0.4353 - precision: 0.4903 - recall: 0.5042 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.6525e-05 - val_precision: 5.7048e-05 - val_recall: 0.9063\n",
            "Epoch 31/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5534 - mean_io_u_2: 0.5139 - f1-score: 0.4504 - precision: 0.5147 - recall: 0.5259 - val_loss: 0.9999 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.3680e-04 - val_precision: 1.6787e-04 - val_recall: 0.9063\n",
            "Epoch 32/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5499 - mean_io_u_2: 0.5128 - f1-score: 0.4538 - precision: 0.5224 - recall: 0.5195 - val_loss: 0.9999 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.6243e-04 - val_precision: 1.9611e-04 - val_recall: 0.9063\n",
            "Epoch 33/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5394 - mean_io_u_2: 0.5166 - f1-score: 0.4644 - precision: 0.5245 - recall: 0.5390 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.5609e-05 - val_precision: 5.7952e-05 - val_recall: 0.9063\n",
            "Epoch 34/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.5459 - mean_io_u_2: 0.5141 - f1-score: 0.4578 - precision: 0.5269 - recall: 0.5294 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 4.4117e-05 - val_precision: 7.4912e-05 - val_recall: 0.9063\n",
            "Epoch 35/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5388 - mean_io_u_2: 0.5199 - f1-score: 0.4650 - precision: 0.5404 - recall: 0.5320 - val_loss: 0.9997 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.0548e-04 - val_precision: 3.6985e-04 - val_recall: 0.9063\n",
            "Epoch 36/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5451 - mean_io_u_2: 0.5092 - f1-score: 0.4587 - precision: 0.5239 - recall: 0.5383 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 5.9164e-05 - val_precision: 6.5269e-05 - val_recall: 0.9063\n",
            "Epoch 37/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5397 - mean_io_u_2: 0.5111 - f1-score: 0.4641 - precision: 0.5258 - recall: 0.5400 - val_loss: 0.9999 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.4614e-04 - val_precision: 1.6941e-04 - val_recall: 0.9063\n",
            "Epoch 38/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5298 - mean_io_u_2: 0.5087 - f1-score: 0.4737 - precision: 0.5402 - recall: 0.5436 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.8043e-05 - val_precision: 5.1152e-05 - val_recall: 0.9063\n",
            "Epoch 39/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5159 - mean_io_u_2: 0.5138 - f1-score: 0.4874 - precision: 0.5639 - recall: 0.5549 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 6.5069e-05 - val_precision: 8.5434e-05 - val_recall: 0.9063\n",
            "Epoch 40/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5124 - mean_io_u_2: 0.5201 - f1-score: 0.4908 - precision: 0.5693 - recall: 0.5530 - val_loss: 0.9998 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.8846e-04 - val_precision: 2.2654e-04 - val_recall: 0.9063\n",
            "Epoch 41/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.5058 - mean_io_u_2: 0.5191 - f1-score: 0.4974 - precision: 0.5733 - recall: 0.5581 - val_loss: 0.9998 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.6752e-04 - val_precision: 3.0820e-04 - val_recall: 0.9063\n",
            "Epoch 42/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.5284 - mean_io_u_2: 0.5188 - f1-score: 0.4750 - precision: 0.5447 - recall: 0.5428 - val_loss: 0.9990 - val_mean_io_u_2: 0.5000 - val_f1-score: 9.9196e-04 - val_precision: 0.0011 - val_recall: 0.9063\n",
            "Epoch 43/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.5278 - mean_io_u_2: 0.5163 - f1-score: 0.4757 - precision: 0.5551 - recall: 0.5404 - val_loss: 0.9997 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.9404e-04 - val_precision: 3.3979e-04 - val_recall: 0.9063\n",
            "Epoch 44/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5087 - mean_io_u_2: 0.5326 - f1-score: 0.4945 - precision: 0.5763 - recall: 0.5596 - val_loss: 0.9997 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.7073e-04 - val_precision: 4.2892e-04 - val_recall: 0.9063\n",
            "Epoch 45/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.5185 - mean_io_u_2: 0.5298 - f1-score: 0.4849 - precision: 0.5535 - recall: 0.5498 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 6.6423e-05 - val_precision: 8.7784e-05 - val_recall: 0.9063\n",
            "Epoch 46/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.5045 - mean_io_u_2: 0.5270 - f1-score: 0.4986 - precision: 0.5871 - recall: 0.5589 - val_loss: 0.9998 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.7233e-04 - val_precision: 3.1827e-04 - val_recall: 0.9063\n",
            "Epoch 47/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5010 - mean_io_u_2: 0.5236 - f1-score: 0.5021 - precision: 0.5777 - recall: 0.5663 - val_loss: 0.9998 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.1850e-04 - val_precision: 2.6106e-04 - val_recall: 0.9063\n",
            "Epoch 48/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.5094 - mean_io_u_2: 0.5271 - f1-score: 0.4938 - precision: 0.5796 - recall: 0.5516 - val_loss: 0.9999 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.4673e-04 - val_precision: 1.7679e-04 - val_recall: 0.9063\n",
            "Epoch 49/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4969 - mean_io_u_2: 0.5305 - f1-score: 0.5061 - precision: 0.5882 - recall: 0.5678 - val_loss: 0.9999 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.1816e-04 - val_precision: 1.5544e-04 - val_recall: 0.9063\n",
            "Epoch 50/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4983 - mean_io_u_2: 0.5270 - f1-score: 0.5047 - precision: 0.5988 - recall: 0.5651 - val_loss: 0.9999 - val_mean_io_u_2: 0.5000 - val_f1-score: 8.9993e-05 - val_precision: 1.1561e-04 - val_recall: 0.9063\n",
            "Epoch 51/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4932 - mean_io_u_2: 0.5295 - f1-score: 0.5098 - precision: 0.5982 - recall: 0.5701 - val_loss: 0.9999 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.7657e-04 - val_precision: 2.1742e-04 - val_recall: 0.9063\n",
            "Epoch 52/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4973 - mean_io_u_2: 0.5289 - f1-score: 0.5058 - precision: 0.5870 - recall: 0.5653 - val_loss: 0.9998 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.2185e-04 - val_precision: 2.5644e-04 - val_recall: 0.9063\n",
            "Epoch 53/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4962 - mean_io_u_2: 0.5319 - f1-score: 0.5067 - precision: 0.6053 - recall: 0.5671 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 4.1912e-05 - val_precision: 6.5339e-05 - val_recall: 0.9063\n",
            "Epoch 54/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4847 - mean_io_u_2: 0.5463 - f1-score: 0.5183 - precision: 0.6046 - recall: 0.5790 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 8.1802e-05 - val_precision: 1.0952e-04 - val_recall: 0.9063\n",
            "Epoch 55/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4857 - mean_io_u_2: 0.5401 - f1-score: 0.5173 - precision: 0.6033 - recall: 0.5804 - val_loss: 0.9996 - val_mean_io_u_2: 0.5000 - val_f1-score: 4.6025e-04 - val_precision: 5.2347e-04 - val_recall: 0.9063\n",
            "Epoch 56/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.5104 - mean_io_u_2: 0.5318 - f1-score: 0.4932 - precision: 0.5892 - recall: 0.5646 - val_loss: 0.9997 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.9046e-04 - val_precision: 3.2597e-04 - val_recall: 0.9063\n",
            "Epoch 57/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.5077 - mean_io_u_2: 0.5298 - f1-score: 0.4961 - precision: 0.5987 - recall: 0.5649 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 5.6104e-05 - val_precision: 7.7307e-05 - val_recall: 0.9063\n",
            "Epoch 58/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4948 - mean_io_u_2: 0.5309 - f1-score: 0.5086 - precision: 0.6086 - recall: 0.5775 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.7921e-05 - val_precision: 4.3612e-05 - val_recall: 0.9063\n",
            "Epoch 59/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4781 - mean_io_u_2: 0.5315 - f1-score: 0.5251 - precision: 0.6218 - recall: 0.5895 - val_loss: 0.9998 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.2522e-04 - val_precision: 2.6228e-04 - val_recall: 0.9063\n",
            "Epoch 60/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4653 - mean_io_u_2: 0.5451 - f1-score: 0.5377 - precision: 0.6366 - recall: 0.5983 - val_loss: 0.9997 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.5873e-04 - val_precision: 4.0922e-04 - val_recall: 0.9063\n",
            "Epoch 61/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.4676 - mean_io_u_2: 0.5358 - f1-score: 0.5355 - precision: 0.6408 - recall: 0.5957 - val_loss: 0.9986 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0015 - val_precision: 0.0016 - val_recall: 0.9063\n",
            "Epoch 62/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4789 - mean_io_u_2: 0.5382 - f1-score: 0.5246 - precision: 0.6215 - recall: 0.5853 - val_loss: 0.9997 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.4990e-04 - val_precision: 3.8826e-04 - val_recall: 0.9063\n",
            "Epoch 63/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4823 - mean_io_u_2: 0.5195 - f1-score: 0.5209 - precision: 0.6166 - recall: 0.5945 - val_loss: 0.9997 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.0245e-04 - val_precision: 3.3895e-04 - val_recall: 0.9063\n",
            "Epoch 64/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.4617 - mean_io_u_2: 0.5536 - f1-score: 0.5420 - precision: 0.6304 - recall: 0.6120 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 8.0747e-05 - val_precision: 1.0589e-04 - val_recall: 0.9063\n",
            "Epoch 65/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.4301 - mean_io_u_2: 0.5455 - f1-score: 0.5728 - precision: 0.6704 - recall: 0.6400 - val_loss: 0.9994 - val_mean_io_u_2: 0.5000 - val_f1-score: 6.1959e-04 - val_precision: 7.0393e-04 - val_recall: 0.9063\n",
            "Epoch 66/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4187 - mean_io_u_2: 0.5482 - f1-score: 0.5840 - precision: 0.6879 - recall: 0.6420 - val_loss: 0.9989 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0011 - val_precision: 0.0013 - val_recall: 0.9063\n",
            "Epoch 67/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4135 - mean_io_u_2: 0.5561 - f1-score: 0.5892 - precision: 0.6824 - recall: 0.6526 - val_loss: 0.9989 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0011 - val_precision: 0.0013 - val_recall: 0.9063\n",
            "Epoch 68/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4218 - mean_io_u_2: 0.5637 - f1-score: 0.5809 - precision: 0.6833 - recall: 0.6393 - val_loss: 0.9995 - val_mean_io_u_2: 0.5000 - val_f1-score: 5.7362e-04 - val_precision: 6.7449e-04 - val_recall: 0.9063\n",
            "Epoch 69/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4144 - mean_io_u_2: 0.5710 - f1-score: 0.5884 - precision: 0.6779 - recall: 0.6537 - val_loss: 0.9996 - val_mean_io_u_2: 0.5000 - val_f1-score: 4.1822e-04 - val_precision: 4.8411e-04 - val_recall: 0.9063\n",
            "Epoch 70/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4080 - mean_io_u_2: 0.5574 - f1-score: 0.5947 - precision: 0.6922 - recall: 0.6543 - val_loss: 0.9986 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0015 - val_precision: 0.0017 - val_recall: 0.9063\n",
            "Epoch 71/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4072 - mean_io_u_2: 0.5614 - f1-score: 0.5954 - precision: 0.6986 - recall: 0.6500 - val_loss: 0.9993 - val_mean_io_u_2: 0.5000 - val_f1-score: 7.1320e-04 - val_precision: 8.2093e-04 - val_recall: 0.9063\n",
            "Epoch 72/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4108 - mean_io_u_2: 0.5616 - f1-score: 0.5918 - precision: 0.6938 - recall: 0.6483 - val_loss: 0.9994 - val_mean_io_u_2: 0.5000 - val_f1-score: 6.3436e-04 - val_precision: 7.3166e-04 - val_recall: 0.9063\n",
            "Epoch 73/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4055 - mean_io_u_2: 0.5701 - f1-score: 0.5971 - precision: 0.6902 - recall: 0.6571 - val_loss: 0.9987 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0013 - val_precision: 0.0015 - val_recall: 0.9063\n",
            "Epoch 74/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4055 - mean_io_u_2: 0.5650 - f1-score: 0.5971 - precision: 0.7069 - recall: 0.6511 - val_loss: 0.9999 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.7519e-04 - val_precision: 2.6783e-04 - val_recall: 0.9063\n",
            "Epoch 75/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4021 - mean_io_u_2: 0.5773 - f1-score: 0.6004 - precision: 0.7098 - recall: 0.6558 - val_loss: 0.9993 - val_mean_io_u_2: 0.5000 - val_f1-score: 7.0100e-04 - val_precision: 9.0134e-04 - val_recall: 0.9063\n",
            "Epoch 76/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4029 - mean_io_u_2: 0.5649 - f1-score: 0.5996 - precision: 0.7116 - recall: 0.6495 - val_loss: 0.9986 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0014 - val_precision: 0.0017 - val_recall: 0.9063\n",
            "Epoch 77/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4004 - mean_io_u_2: 0.5862 - f1-score: 0.6021 - precision: 0.7127 - recall: 0.6549 - val_loss: 0.9989 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0011 - val_precision: 0.0013 - val_recall: 0.9063\n",
            "Epoch 78/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3989 - mean_io_u_2: 0.5936 - f1-score: 0.6036 - precision: 0.7103 - recall: 0.6602 - val_loss: 0.9987 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0014 - val_precision: 0.0016 - val_recall: 0.9063\n",
            "Epoch 79/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3982 - mean_io_u_2: 0.5928 - f1-score: 0.6042 - precision: 0.7119 - recall: 0.6563 - val_loss: 0.9960 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0040 - val_precision: 0.0044 - val_recall: 0.9063\n",
            "Epoch 80/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4020 - mean_io_u_2: 0.5955 - f1-score: 0.6004 - precision: 0.7129 - recall: 0.6516 - val_loss: 0.9995 - val_mean_io_u_2: 0.5000 - val_f1-score: 5.4071e-04 - val_precision: 6.5598e-04 - val_recall: 0.9063\n",
            "Epoch 81/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4080 - mean_io_u_2: 0.5977 - f1-score: 0.5946 - precision: 0.7134 - recall: 0.6412 - val_loss: 0.9976 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0024 - val_precision: 0.0027 - val_recall: 0.9063\n",
            "Epoch 82/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4158 - mean_io_u_2: 0.5933 - f1-score: 0.5871 - precision: 0.6875 - recall: 0.6474 - val_loss: 0.9998 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.6896e-04 - val_precision: 4.3294e-04 - val_recall: 0.9063\n",
            "Epoch 83/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4021 - mean_io_u_2: 0.5977 - f1-score: 0.6005 - precision: 0.7079 - recall: 0.6528 - val_loss: 0.9995 - val_mean_io_u_2: 0.5000 - val_f1-score: 5.8526e-04 - val_precision: 7.1332e-04 - val_recall: 0.9063\n",
            "Epoch 84/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3935 - mean_io_u_2: 0.5954 - f1-score: 0.6089 - precision: 0.7213 - recall: 0.6615 - val_loss: 0.9965 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0035 - val_precision: 0.0039 - val_recall: 0.9063\n",
            "Epoch 85/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3956 - mean_io_u_2: 0.6091 - f1-score: 0.6068 - precision: 0.7226 - recall: 0.6595 - val_loss: 0.9861 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0139 - val_precision: 0.0155 - val_recall: 0.9063\n",
            "Epoch 86/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3948 - mean_io_u_2: 0.5978 - f1-score: 0.6077 - precision: 0.7149 - recall: 0.6619 - val_loss: 0.9952 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0049 - val_precision: 0.0054 - val_recall: 0.9063\n",
            "Epoch 87/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4004 - mean_io_u_2: 0.6108 - f1-score: 0.6022 - precision: 0.7048 - recall: 0.6548 - val_loss: 0.9999 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.8019e-04 - val_precision: 2.9584e-04 - val_recall: 0.9063\n",
            "Epoch 88/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4011 - mean_io_u_2: 0.6102 - f1-score: 0.6015 - precision: 0.7084 - recall: 0.6565 - val_loss: 0.9969 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0031 - val_precision: 0.0035 - val_recall: 0.9063\n",
            "Epoch 89/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3907 - mean_io_u_2: 0.6291 - f1-score: 0.6117 - precision: 0.7192 - recall: 0.6661 - val_loss: 0.9996 - val_mean_io_u_2: 0.5000 - val_f1-score: 4.5341e-04 - val_precision: 5.7686e-04 - val_recall: 0.9063\n",
            "Epoch 90/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3922 - mean_io_u_2: 0.6227 - f1-score: 0.6103 - precision: 0.7253 - recall: 0.6601 - val_loss: 0.9999 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.3474e-04 - val_precision: 1.9446e-04 - val_recall: 0.9063\n",
            "Epoch 91/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3880 - mean_io_u_2: 0.6249 - f1-score: 0.6144 - precision: 0.7269 - recall: 0.6650 - val_loss: 0.9995 - val_mean_io_u_2: 0.5000 - val_f1-score: 5.7650e-04 - val_precision: 7.0037e-04 - val_recall: 0.9063\n",
            "Epoch 92/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3898 - mean_io_u_2: 0.6333 - f1-score: 0.6127 - precision: 0.7307 - recall: 0.6616 - val_loss: 0.9998 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.2609e-04 - val_precision: 3.6989e-04 - val_recall: 0.9063\n",
            "Epoch 93/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3895 - mean_io_u_2: 0.6283 - f1-score: 0.6130 - precision: 0.7197 - recall: 0.6660 - val_loss: 0.9980 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0021 - val_precision: 0.0023 - val_recall: 0.9063\n",
            "Epoch 94/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3881 - mean_io_u_2: 0.6200 - f1-score: 0.6142 - precision: 0.7321 - recall: 0.6630 - val_loss: 0.9992 - val_mean_io_u_2: 0.5000 - val_f1-score: 8.3022e-04 - val_precision: 0.0010 - val_recall: 0.9063\n",
            "Epoch 95/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3848 - mean_io_u_2: 0.6359 - f1-score: 0.6175 - precision: 0.7314 - recall: 0.6673 - val_loss: 0.9977 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0023 - val_precision: 0.0026 - val_recall: 0.9063\n",
            "Epoch 96/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3896 - mean_io_u_2: 0.6536 - f1-score: 0.6129 - precision: 0.7257 - recall: 0.6628 - val_loss: 0.9998 - val_mean_io_u_2: 0.5000 - val_f1-score: 1.9136e-04 - val_precision: 3.3050e-04 - val_recall: 0.9063\n",
            "Epoch 97/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3849 - mean_io_u_2: 0.6379 - f1-score: 0.6175 - precision: 0.7401 - recall: 0.6643 - val_loss: 0.9997 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.0961e-04 - val_precision: 5.7895e-04 - val_recall: 0.9063\n",
            "Epoch 98/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3817 - mean_io_u_2: 0.6484 - f1-score: 0.6206 - precision: 0.7446 - recall: 0.6677 - val_loss: 0.9962 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0038 - val_precision: 0.0042 - val_recall: 0.9063\n",
            "Epoch 99/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3899 - mean_io_u_2: 0.6109 - f1-score: 0.6125 - precision: 0.7271 - recall: 0.6614 - val_loss: 0.9998 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.5468e-04 - val_precision: 3.5568e-04 - val_recall: 0.9063\n",
            "Epoch 100/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3846 - mean_io_u_2: 0.6210 - f1-score: 0.6177 - precision: 0.7275 - recall: 0.6701 - val_loss: 0.9983 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0018 - val_precision: 0.0019 - val_recall: 0.9063\n",
            "Epoch 101/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3806 - mean_io_u_2: 0.6367 - f1-score: 0.6217 - precision: 0.7425 - recall: 0.6708 - val_loss: 0.9926 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0074 - val_precision: 0.0082 - val_recall: 0.9063\n",
            "Epoch 102/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3872 - mean_io_u_2: 0.6487 - f1-score: 0.6152 - precision: 0.7276 - recall: 0.6678 - val_loss: 0.9828 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0172 - val_precision: 0.0191 - val_recall: 0.9063\n",
            "Epoch 103/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3807 - mean_io_u_2: 0.6410 - f1-score: 0.6217 - precision: 0.7408 - recall: 0.6710 - val_loss: 0.9942 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0059 - val_precision: 0.0066 - val_recall: 0.9063\n",
            "Epoch 104/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3848 - mean_io_u_2: 0.6557 - f1-score: 0.6176 - precision: 0.7288 - recall: 0.6675 - val_loss: 0.9915 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0086 - val_precision: 0.0096 - val_recall: 0.9063\n",
            "Epoch 105/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3809 - mean_io_u_2: 0.6371 - f1-score: 0.6215 - precision: 0.7301 - recall: 0.6729 - val_loss: 0.9916 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0084 - val_precision: 0.0093 - val_recall: 0.9063\n",
            "Epoch 106/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3811 - mean_io_u_2: 0.6491 - f1-score: 0.6212 - precision: 0.7320 - recall: 0.6727 - val_loss: 0.9339 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0662 - val_precision: 0.0730 - val_recall: 0.9063\n",
            "Epoch 107/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3749 - mean_io_u_2: 0.6482 - f1-score: 0.6273 - precision: 0.7436 - recall: 0.6735 - val_loss: 0.9830 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0171 - val_precision: 0.0188 - val_recall: 0.9063\n",
            "Epoch 108/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3784 - mean_io_u_2: 0.6576 - f1-score: 0.6240 - precision: 0.7400 - recall: 0.6726 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 7.0461e-05 - val_precision: 1.5198e-04 - val_recall: 0.9063\n",
            "Epoch 109/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3753 - mean_io_u_2: 0.6718 - f1-score: 0.6270 - precision: 0.7498 - recall: 0.6740 - val_loss: 0.9994 - val_mean_io_u_2: 0.5000 - val_f1-score: 6.3145e-04 - val_precision: 7.5533e-04 - val_recall: 0.9063\n",
            "Epoch 110/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3738 - mean_io_u_2: 0.6682 - f1-score: 0.6285 - precision: 0.7495 - recall: 0.6768 - val_loss: 0.9792 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0208 - val_precision: 0.0229 - val_recall: 0.9063\n",
            "Epoch 111/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3771 - mean_io_u_2: 0.6739 - f1-score: 0.6252 - precision: 0.7478 - recall: 0.6743 - val_loss: 0.9991 - val_mean_io_u_2: 0.5000 - val_f1-score: 8.9484e-04 - val_precision: 0.0011 - val_recall: 0.9063\n",
            "Epoch 112/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3807 - mean_io_u_2: 0.6595 - f1-score: 0.6217 - precision: 0.7422 - recall: 0.6672 - val_loss: 0.9692 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0308 - val_precision: 0.0340 - val_recall: 0.9063\n",
            "Epoch 113/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3751 - mean_io_u_2: 0.6474 - f1-score: 0.6272 - precision: 0.7432 - recall: 0.6774 - val_loss: 0.9889 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0112 - val_precision: 0.0123 - val_recall: 0.9063\n",
            "Epoch 114/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.3797 - mean_io_u_2: 0.6516 - f1-score: 0.6226 - precision: 0.7458 - recall: 0.6705 - val_loss: 0.9941 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0059 - val_precision: 0.0065 - val_recall: 0.9063\n",
            "Epoch 115/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3829 - mean_io_u_2: 0.6408 - f1-score: 0.6194 - precision: 0.7359 - recall: 0.6659 - val_loss: 0.9997 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.3945e-04 - val_precision: 4.1400e-04 - val_recall: 0.9063\n",
            "Epoch 116/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3753 - mean_io_u_2: 0.6581 - f1-score: 0.6270 - precision: 0.7498 - recall: 0.6727 - val_loss: 0.9978 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0022 - val_precision: 0.0026 - val_recall: 0.9063\n",
            "Epoch 117/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3705 - mean_io_u_2: 0.6751 - f1-score: 0.6318 - precision: 0.7531 - recall: 0.6765 - val_loss: 0.9988 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0013 - val_precision: 0.0014 - val_recall: 0.9063\n",
            "Epoch 118/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3708 - mean_io_u_2: 0.6683 - f1-score: 0.6315 - precision: 0.7526 - recall: 0.6772 - val_loss: 0.9986 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0014 - val_precision: 0.0016 - val_recall: 0.9063\n",
            "Epoch 119/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3709 - mean_io_u_2: 0.6690 - f1-score: 0.6314 - precision: 0.7420 - recall: 0.6799 - val_loss: 0.9894 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0106 - val_precision: 0.0118 - val_recall: 0.9063\n",
            "Epoch 120/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3681 - mean_io_u_2: 0.6875 - f1-score: 0.6342 - precision: 0.7545 - recall: 0.6799 - val_loss: 0.9753 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0248 - val_precision: 0.0273 - val_recall: 0.9063\n",
            "Epoch 121/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3654 - mean_io_u_2: 0.6889 - f1-score: 0.6369 - precision: 0.7584 - recall: 0.6816 - val_loss: 1.0000 - val_mean_io_u_2: 0.5000 - val_f1-score: 3.4733e-05 - val_precision: 8.2568e-05 - val_recall: 0.9063\n",
            "Epoch 122/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3662 - mean_io_u_2: 0.6784 - f1-score: 0.6360 - precision: 0.7512 - recall: 0.6829 - val_loss: 0.9920 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0080 - val_precision: 0.0089 - val_recall: 0.9063\n",
            "Epoch 123/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3702 - mean_io_u_2: 0.6878 - f1-score: 0.6321 - precision: 0.7510 - recall: 0.6803 - val_loss: 0.9966 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0034 - val_precision: 0.0038 - val_recall: 0.9063\n",
            "Epoch 124/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3773 - mean_io_u_2: 0.6723 - f1-score: 0.6250 - precision: 0.7493 - recall: 0.6719 - val_loss: 0.9746 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0254 - val_precision: 0.0281 - val_recall: 0.9063\n",
            "Epoch 125/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3718 - mean_io_u_2: 0.6647 - f1-score: 0.6304 - precision: 0.7510 - recall: 0.6781 - val_loss: 0.9618 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0382 - val_precision: 0.0421 - val_recall: 0.9063\n",
            "Epoch 126/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3735 - mean_io_u_2: 0.6817 - f1-score: 0.6288 - precision: 0.7487 - recall: 0.6757 - val_loss: 0.9991 - val_mean_io_u_2: 0.5000 - val_f1-score: 9.5660e-04 - val_precision: 0.0011 - val_recall: 0.9063\n",
            "Epoch 127/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3702 - mean_io_u_2: 0.6635 - f1-score: 0.6322 - precision: 0.7503 - recall: 0.6799 - val_loss: 0.9860 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0141 - val_precision: 0.0155 - val_recall: 0.9063\n",
            "Epoch 128/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3690 - mean_io_u_2: 0.6853 - f1-score: 0.6333 - precision: 0.7532 - recall: 0.6801 - val_loss: 0.9916 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0084 - val_precision: 0.0093 - val_recall: 0.9063\n",
            "Epoch 129/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3668 - mean_io_u_2: 0.6814 - f1-score: 0.6355 - precision: 0.7581 - recall: 0.6774 - val_loss: 0.8722 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.1279 - val_precision: 0.1411 - val_recall: 0.9063\n",
            "Epoch 130/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3653 - mean_io_u_2: 0.6917 - f1-score: 0.6369 - precision: 0.7654 - recall: 0.6794 - val_loss: 0.9958 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0042 - val_precision: 0.0047 - val_recall: 0.9063\n",
            "Epoch 131/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3660 - mean_io_u_2: 0.6813 - f1-score: 0.6363 - precision: 0.7555 - recall: 0.6825 - val_loss: 0.9151 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0849 - val_precision: 0.0937 - val_recall: 0.9063\n",
            "Epoch 132/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3651 - mean_io_u_2: 0.6880 - f1-score: 0.6371 - precision: 0.7562 - recall: 0.6815 - val_loss: 0.9382 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0618 - val_precision: 0.0682 - val_recall: 0.9063\n",
            "Epoch 133/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3648 - mean_io_u_2: 0.7012 - f1-score: 0.6375 - precision: 0.7656 - recall: 0.6798 - val_loss: 0.9984 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0016 - val_precision: 0.0019 - val_recall: 0.9063\n",
            "Epoch 134/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3647 - mean_io_u_2: 0.7136 - f1-score: 0.6376 - precision: 0.7635 - recall: 0.6820 - val_loss: 0.9985 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0015 - val_precision: 0.0017 - val_recall: 0.9063\n",
            "Epoch 135/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3692 - mean_io_u_2: 0.7079 - f1-score: 0.6332 - precision: 0.7535 - recall: 0.6780 - val_loss: 0.8566 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.1435 - val_precision: 0.1583 - val_recall: 0.9063\n",
            "Epoch 136/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3661 - mean_io_u_2: 0.7036 - f1-score: 0.6362 - precision: 0.7553 - recall: 0.6811 - val_loss: 0.9153 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0847 - val_precision: 0.0935 - val_recall: 0.9063\n",
            "Epoch 137/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3639 - mean_io_u_2: 0.6934 - f1-score: 0.6384 - precision: 0.7562 - recall: 0.6834 - val_loss: 0.9936 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0064 - val_precision: 0.0071 - val_recall: 0.9063\n",
            "Epoch 138/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3641 - mean_io_u_2: 0.6999 - f1-score: 0.6381 - precision: 0.7597 - recall: 0.6829 - val_loss: 0.9811 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0190 - val_precision: 0.0210 - val_recall: 0.9063\n",
            "Epoch 139/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.3589 - mean_io_u_2: 0.6925 - f1-score: 0.6433 - precision: 0.7686 - recall: 0.6864 - val_loss: 0.9785 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0215 - val_precision: 0.0238 - val_recall: 0.9063\n",
            "Epoch 140/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3584 - mean_io_u_2: 0.6859 - f1-score: 0.6438 - precision: 0.7706 - recall: 0.6865 - val_loss: 0.9120 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0881 - val_precision: 0.0970 - val_recall: 0.9063\n",
            "Epoch 141/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3619 - mean_io_u_2: 0.6848 - f1-score: 0.6403 - precision: 0.7651 - recall: 0.6845 - val_loss: 0.9693 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0307 - val_precision: 0.0339 - val_recall: 0.9063\n",
            "Epoch 142/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3597 - mean_io_u_2: 0.6975 - f1-score: 0.6424 - precision: 0.7686 - recall: 0.6850 - val_loss: 0.9940 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0060 - val_precision: 0.0067 - val_recall: 0.9063\n",
            "Epoch 143/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3582 - mean_io_u_2: 0.7058 - f1-score: 0.6439 - precision: 0.7699 - recall: 0.6863 - val_loss: 0.9420 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0580 - val_precision: 0.0640 - val_recall: 0.9063\n",
            "Epoch 144/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3590 - mean_io_u_2: 0.6856 - f1-score: 0.6431 - precision: 0.7717 - recall: 0.6844 - val_loss: 0.9906 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0094 - val_precision: 0.0104 - val_recall: 0.9063\n",
            "Epoch 145/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3611 - mean_io_u_2: 0.6955 - f1-score: 0.6412 - precision: 0.7621 - recall: 0.6836 - val_loss: 0.9104 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0896 - val_precision: 0.0989 - val_recall: 0.9063\n",
            "Epoch 146/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.3613 - mean_io_u_2: 0.6950 - f1-score: 0.6409 - precision: 0.7639 - recall: 0.6841 - val_loss: 0.9940 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0060 - val_precision: 0.0067 - val_recall: 0.9063\n",
            "Epoch 147/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.3598 - mean_io_u_2: 0.7034 - f1-score: 0.6424 - precision: 0.7668 - recall: 0.6846 - val_loss: 0.9891 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0110 - val_precision: 0.0122 - val_recall: 0.9063\n",
            "Epoch 148/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3651 - mean_io_u_2: 0.6912 - f1-score: 0.6372 - precision: 0.7580 - recall: 0.6814 - val_loss: 0.9039 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0962 - val_precision: 0.1061 - val_recall: 0.9063\n",
            "Epoch 149/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3616 - mean_io_u_2: 0.7013 - f1-score: 0.6407 - precision: 0.7601 - recall: 0.6858 - val_loss: 0.9440 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0560 - val_precision: 0.0618 - val_recall: 0.9063\n",
            "Epoch 150/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3581 - mean_io_u_2: 0.7007 - f1-score: 0.6440 - precision: 0.7766 - recall: 0.6870 - val_loss: 0.9880 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0120 - val_precision: 0.0133 - val_recall: 0.9063\n",
            "Epoch 151/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3556 - mean_io_u_2: 0.7043 - f1-score: 0.6465 - precision: 0.7702 - recall: 0.6898 - val_loss: 0.9995 - val_mean_io_u_2: 0.5000 - val_f1-score: 4.9264e-04 - val_precision: 5.7005e-04 - val_recall: 0.9063\n",
            "Epoch 152/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3592 - mean_io_u_2: 0.7021 - f1-score: 0.6430 - precision: 0.7752 - recall: 0.6829 - val_loss: 0.7727 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.2274 - val_precision: 0.2509 - val_recall: 0.9063\n",
            "Epoch 153/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4363 - mean_io_u_2: 0.6472 - f1-score: 0.5680 - precision: 0.6905 - recall: 0.6296 - val_loss: 0.8201 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.1800 - val_precision: 0.1986 - val_recall: 0.9063\n",
            "Epoch 154/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3689 - mean_io_u_2: 0.6681 - f1-score: 0.6335 - precision: 0.7624 - recall: 0.6783 - val_loss: 0.7834 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.2167 - val_precision: 0.2391 - val_recall: 0.9063\n",
            "Epoch 155/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3600 - mean_io_u_2: 0.6909 - f1-score: 0.6422 - precision: 0.7713 - recall: 0.6852 - val_loss: 0.7592 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.2408 - val_precision: 0.2656 - val_recall: 0.9063\n",
            "Epoch 156/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3559 - mean_io_u_2: 0.6892 - f1-score: 0.6463 - precision: 0.7679 - recall: 0.6911 - val_loss: 0.9459 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0542 - val_precision: 0.0598 - val_recall: 0.9063\n",
            "Epoch 157/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3533 - mean_io_u_2: 0.7018 - f1-score: 0.6489 - precision: 0.7813 - recall: 0.6900 - val_loss: 0.9312 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0688 - val_precision: 0.0759 - val_recall: 0.9063\n",
            "Epoch 158/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3542 - mean_io_u_2: 0.6984 - f1-score: 0.6479 - precision: 0.7813 - recall: 0.6894 - val_loss: 0.9269 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0731 - val_precision: 0.0806 - val_recall: 0.9063\n",
            "Epoch 159/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3513 - mean_io_u_2: 0.6985 - f1-score: 0.6508 - precision: 0.7804 - recall: 0.6925 - val_loss: 0.9971 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0030 - val_precision: 0.0033 - val_recall: 0.9063\n",
            "Epoch 160/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3543 - mean_io_u_2: 0.7039 - f1-score: 0.6479 - precision: 0.7692 - recall: 0.6905 - val_loss: 0.8502 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.1499 - val_precision: 0.1651 - val_recall: 0.9063\n",
            "Epoch 161/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3508 - mean_io_u_2: 0.7177 - f1-score: 0.6514 - precision: 0.7743 - recall: 0.6942 - val_loss: 0.1582 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.8419 - val_precision: 0.9290 - val_recall: 0.9063\n",
            "Epoch 162/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3503 - mean_io_u_2: 0.7197 - f1-score: 0.6518 - precision: 0.7775 - recall: 0.6932 - val_loss: 0.9790 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0210 - val_precision: 0.0231 - val_recall: 0.9063\n",
            "Epoch 163/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3508 - mean_io_u_2: 0.7192 - f1-score: 0.6514 - precision: 0.7782 - recall: 0.6934 - val_loss: 0.7306 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.2694 - val_precision: 0.2972 - val_recall: 0.9063\n",
            "Epoch 164/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3567 - mean_io_u_2: 0.7178 - f1-score: 0.6455 - precision: 0.7727 - recall: 0.6878 - val_loss: 0.9327 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0674 - val_precision: 0.0744 - val_recall: 0.9063\n",
            "Epoch 165/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3593 - mean_io_u_2: 0.6996 - f1-score: 0.6429 - precision: 0.7620 - recall: 0.6864 - val_loss: 0.8549 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.1451 - val_precision: 0.1599 - val_recall: 0.9063\n",
            "Epoch 166/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3563 - mean_io_u_2: 0.7212 - f1-score: 0.6459 - precision: 0.7697 - recall: 0.6893 - val_loss: 0.9569 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0431 - val_precision: 0.0476 - val_recall: 0.9063\n",
            "Epoch 167/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3554 - mean_io_u_2: 0.7258 - f1-score: 0.6469 - precision: 0.7665 - recall: 0.6916 - val_loss: 0.8221 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.1779 - val_precision: 0.1963 - val_recall: 0.9063\n",
            "Epoch 168/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3547 - mean_io_u_2: 0.7168 - f1-score: 0.6474 - precision: 0.7712 - recall: 0.6901 - val_loss: 0.5090 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.4910 - val_precision: 0.5418 - val_recall: 0.9063\n",
            "Epoch 169/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3521 - mean_io_u_2: 0.7166 - f1-score: 0.6500 - precision: 0.7803 - recall: 0.6913 - val_loss: 0.9276 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0725 - val_precision: 0.0798 - val_recall: 0.9063\n",
            "Epoch 170/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3496 - mean_io_u_2: 0.7224 - f1-score: 0.6525 - precision: 0.7813 - recall: 0.6931 - val_loss: 0.9131 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0869 - val_precision: 0.0960 - val_recall: 0.9063\n",
            "Epoch 171/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3502 - mean_io_u_2: 0.7203 - f1-score: 0.6519 - precision: 0.7769 - recall: 0.6936 - val_loss: 0.7814 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.2187 - val_precision: 0.2413 - val_recall: 0.9063\n",
            "Epoch 172/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3554 - mean_io_u_2: 0.7159 - f1-score: 0.6467 - precision: 0.7797 - recall: 0.6882 - val_loss: 0.9998 - val_mean_io_u_2: 0.5000 - val_f1-score: 2.7886e-04 - val_precision: 3.1619e-04 - val_recall: 0.9063\n",
            "Epoch 173/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.3560 - mean_io_u_2: 0.7138 - f1-score: 0.6461 - precision: 0.7719 - recall: 0.6889 - val_loss: 0.7616 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.2384 - val_precision: 0.2630 - val_recall: 0.9063\n",
            "Epoch 174/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3520 - mean_io_u_2: 0.7207 - f1-score: 0.6502 - precision: 0.7762 - recall: 0.6921 - val_loss: 0.4651 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.5350 - val_precision: 0.5903 - val_recall: 0.9063\n",
            "Epoch 175/200\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.3535 - mean_io_u_2: 0.7217 - f1-score: 0.6486 - precision: 0.7776 - recall: 0.6902 - val_loss: 0.9979 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0021 - val_precision: 0.0024 - val_recall: 0.9063\n",
            "Epoch 176/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3499 - mean_io_u_2: 0.7157 - f1-score: 0.6522 - precision: 0.7817 - recall: 0.6918 - val_loss: 0.7857 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.2143 - val_precision: 0.2365 - val_recall: 0.9063\n",
            "Epoch 177/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3465 - mean_io_u_2: 0.7244 - f1-score: 0.6556 - precision: 0.7857 - recall: 0.6969 - val_loss: 0.9392 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0609 - val_precision: 0.0671 - val_recall: 0.9063\n",
            "Epoch 178/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3485 - mean_io_u_2: 0.7270 - f1-score: 0.6536 - precision: 0.7779 - recall: 0.6949 - val_loss: 0.7185 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.2816 - val_precision: 0.3106 - val_recall: 0.9063\n",
            "Epoch 179/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3473 - mean_io_u_2: 0.7242 - f1-score: 0.6547 - precision: 0.7829 - recall: 0.6955 - val_loss: 0.5130 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.4870 - val_precision: 0.5375 - val_recall: 0.9063\n",
            "Epoch 180/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3488 - mean_io_u_2: 0.7234 - f1-score: 0.6532 - precision: 0.7768 - recall: 0.6953 - val_loss: 0.7829 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.2171 - val_precision: 0.2395 - val_recall: 0.9063\n",
            "Epoch 181/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3485 - mean_io_u_2: 0.7257 - f1-score: 0.6537 - precision: 0.7759 - recall: 0.6954 - val_loss: 0.8782 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.1218 - val_precision: 0.1345 - val_recall: 0.9063\n",
            "Epoch 182/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3486 - mean_io_u_2: 0.7255 - f1-score: 0.6535 - precision: 0.7794 - recall: 0.6942 - val_loss: 0.8828 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.1172 - val_precision: 0.1293 - val_recall: 0.9063\n",
            "Epoch 183/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3500 - mean_io_u_2: 0.7227 - f1-score: 0.6521 - precision: 0.7812 - recall: 0.6932 - val_loss: 0.9897 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0103 - val_precision: 0.0114 - val_recall: 0.9063\n",
            "Epoch 184/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3503 - mean_io_u_2: 0.7155 - f1-score: 0.6517 - precision: 0.7717 - recall: 0.6932 - val_loss: 0.9408 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0593 - val_precision: 0.0654 - val_recall: 0.9063\n",
            "Epoch 185/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3463 - mean_io_u_2: 0.7245 - f1-score: 0.6558 - precision: 0.7795 - recall: 0.6977 - val_loss: 0.2937 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.7064 - val_precision: 0.7793 - val_recall: 0.9063\n",
            "Epoch 186/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3497 - mean_io_u_2: 0.7282 - f1-score: 0.6524 - precision: 0.7776 - recall: 0.6952 - val_loss: 0.9736 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0264 - val_precision: 0.0291 - val_recall: 0.9063\n",
            "Epoch 187/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3463 - mean_io_u_2: 0.7397 - f1-score: 0.6559 - precision: 0.7876 - recall: 0.6965 - val_loss: 0.9137 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0863 - val_precision: 0.0953 - val_recall: 0.9063\n",
            "Epoch 188/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3500 - mean_io_u_2: 0.7283 - f1-score: 0.6523 - precision: 0.7830 - recall: 0.6927 - val_loss: 0.6707 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.3293 - val_precision: 0.3634 - val_recall: 0.9063\n",
            "Epoch 189/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3449 - mean_io_u_2: 0.7265 - f1-score: 0.6573 - precision: 0.7879 - recall: 0.6980 - val_loss: 0.5455 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.4545 - val_precision: 0.5015 - val_recall: 0.9063\n",
            "Epoch 190/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3438 - mean_io_u_2: 0.7284 - f1-score: 0.6583 - precision: 0.7861 - recall: 0.6989 - val_loss: 0.9597 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.0403 - val_precision: 0.0445 - val_recall: 0.9063\n",
            "Epoch 191/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3411 - mean_io_u_2: 0.7300 - f1-score: 0.6614 - precision: 0.7798 - recall: 0.7095 - val_loss: 0.1087 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.8913 - val_precision: 0.9835 - val_recall: 0.9063\n",
            "Epoch 192/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4317 - mean_io_u_2: 0.6849 - f1-score: 0.5715 - precision: 0.7303 - recall: 0.6022 - val_loss: 0.0941 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.9060 - val_precision: 0.9997 - val_recall: 0.9063\n",
            "Epoch 193/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.4133 - mean_io_u_2: 0.6032 - f1-score: 0.5899 - precision: 0.7407 - recall: 0.5874 - val_loss: 0.0950 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.9050 - val_precision: 0.9987 - val_recall: 0.9063\n",
            "Epoch 194/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3525 - mean_io_u_2: 0.6144 - f1-score: 0.6501 - precision: 0.7981 - recall: 0.6427 - val_loss: 0.0941 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.9059 - val_precision: 0.9996 - val_recall: 0.9063\n",
            "Epoch 195/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3287 - mean_io_u_2: 0.6252 - f1-score: 0.6737 - precision: 0.8113 - recall: 0.6650 - val_loss: 0.0941 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.9059 - val_precision: 0.9996 - val_recall: 0.9063\n",
            "Epoch 196/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3124 - mean_io_u_2: 0.6553 - f1-score: 0.6899 - precision: 0.8319 - recall: 0.6760 - val_loss: 0.0941 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.9059 - val_precision: 0.9996 - val_recall: 0.9063\n",
            "Epoch 197/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3055 - mean_io_u_2: 0.6739 - f1-score: 0.6967 - precision: 0.8456 - recall: 0.6827 - val_loss: 0.0942 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.9058 - val_precision: 0.9995 - val_recall: 0.9063\n",
            "Epoch 198/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.3010 - mean_io_u_2: 0.6849 - f1-score: 0.7012 - precision: 0.8446 - recall: 0.6874 - val_loss: 0.0942 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.9059 - val_precision: 0.9996 - val_recall: 0.9063\n",
            "Epoch 199/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.2973 - mean_io_u_2: 0.6938 - f1-score: 0.7049 - precision: 0.8448 - recall: 0.6918 - val_loss: 0.0941 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.9059 - val_precision: 0.9996 - val_recall: 0.9063\n",
            "Epoch 200/200\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.2936 - mean_io_u_2: 0.7071 - f1-score: 0.7086 - precision: 0.8506 - recall: 0.6948 - val_loss: 0.0941 - val_mean_io_u_2: 0.5000 - val_f1-score: 0.9059 - val_precision: 0.9996 - val_recall: 0.9063\n"
          ]
        }
      ],
      "source": [
        "#Si uso el custom datagen\n",
        "steps_per_epoch = len(train_img_list)//batch_size\n",
        "val_steps_per_epoch = len(val_img_list)//batch_size\n",
        "\n",
        "history=model.fit(train_img_datagen,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=200,\n",
        "          verbose=1,\n",
        "          validation_data=val_img_datagen,\n",
        "          validation_steps=val_steps_per_epoch,\n",
        "          )\n",
        "\n",
        "model.save('modelo_1.2.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "#plot the training and validation IoU and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "f1 = history.history['f1-score']\n",
        "\n",
        "plt.plot(epochs, f1, 'y', label='Training f1')\n",
        "plt.title('Training and validation f1-score')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('f1-score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "JQAT07EfmcZg",
        "outputId": "78814b22-de0e-4ec4-ee16-1277d4886058"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}