{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPo4XoSdiKoBpH3eadFceZh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmcastillo/al112248/blob/main/organizar_imagenes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XkidcnwpFbJL"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------------------------------------------------\n",
        "#--------------------Código para organizar dataset en carpetas train/val/test--------------------------\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "#Necesario para llamar por lotes el conjunto de entrenamiento \n",
        "#1. Se cargan los volúmenes de los pacientes caso por caso \n",
        "#2. Se reescalan y normalizan para obtener volúmenes de 512x512x128 (originalmente son de ~512x512x140)\n",
        "#3. Se cambia el tipo de dato de float64 a float32 para las imágenes y a uint8 para las máscaras\n",
        "#4. Guardo los volúmenes en una carpeta como archivos .npy\n",
        "#5. Se manda llamar la carpeta y se sortean en nuevas carpetas train/val/test "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs_34XdpYWIz",
        "outputId": "71a28067-1baa-4ab5-86a8-b9c58a789d99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/');\n",
        "import nibabel as nib\n",
        "from scipy import ndimage\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "import glob"
      ],
      "metadata": {
        "id": "cxkmsHFsGPcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ad73f7-87dd-427d-ccf9-0146adbbaddb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_volume(img):\n",
        "    # Set the desired depth\n",
        "    desired_depth = 128\n",
        "    desired_width = 512\n",
        "    desired_height = 512\n",
        "    # Get current depth\n",
        "    current_depth = img.shape[-1]\n",
        "    current_width = img.shape[0]\n",
        "    current_height = img.shape[1]\n",
        "    # Compute depth factor\n",
        "    depth = current_depth / desired_depth\n",
        "    width = current_width / desired_width\n",
        "    height = current_height / desired_height\n",
        "    depth_factor = 1 / depth\n",
        "    width_factor = 1 / width\n",
        "    height_factor = 1 / height\n",
        "    # Resize across z-axis\n",
        "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
        "    return img"
      ],
      "metadata": {
        "id": "4cHRFF_lZl7H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Carga las imágenes y máscaras nifti, las reescala a 512x512x128 y normaliza y las guarda en dos carpetas (imgs, masks) \n",
        "ruta_TOF = '/content/drive/MyDrive/DOCTORADO/python/adam_subset/train_images/';\n",
        "lista_archivos_TOF = sorted(glob.glob(ruta_TOF+'*.nii.gz'))\n",
        "ruta_mascaras = '/content/drive/MyDrive/DOCTORADO/python/adam_subset/train_tags/'; \n",
        "lista_archivos_mascaras = sorted(glob.glob(ruta_mascaras+'*.nii.gz'))\n",
        "\n",
        "n_casos=10; #10 controles y 10 aneurismas \n",
        "\n",
        "ruta_destino_imgs = '/content/drive/MyDrive/DOCTORADO/python/ADAM_10C_10A_npy/imgs/';\n",
        "ruta_destino_mascs = '/content/drive/MyDrive/DOCTORADO/python/ADAM_10C_10A_npy/masks/';\n",
        "\n",
        "for i in range(len(lista_archivos_TOF)):\n",
        "        data = nib.load(lista_archivos_TOF[i])\n",
        "        temp = data.get_fdata()\n",
        "        temp = resize_volume(temp)\n",
        "        tmp = temp.astype(float)\n",
        "        if i<n_casos:\n",
        "          np.save(ruta_destino_imgs+'C'+str(i+1)+'.npy', temp)\n",
        "        else:  \n",
        "          np.save(ruta_destino_imgs+'A'+str(i-n_casos+1)+'.npy', temp)\n",
        "\n",
        "for i in range(len(lista_archivos_mascaras)):\n",
        "        datam = nib.load(lista_archivos_mascaras[i])\n",
        "        tempm = datam.get_fdata()\n",
        "        tempm = resize_volume(tempm)\n",
        "        tempm = np.where(tempm>0,1,0)\n",
        "        tempm = tempm.astype(np.uint8)\n",
        "        if i<n_casos:\n",
        "          np.save(ruta_destino_mascs+'C'+str(i+1)+'.npy', tempm)\n",
        "        else:  \n",
        "          np.save(ruta_destino_mascs+'A'+str(i-n_casos+1)+'.npy', tempm)"
      ],
      "metadata": {
        "id": "NYiR9bGwG0mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sortea las imágenes y las máscaras en carpetas train/validation/test especificando el porcentaje de cada conjunto\n",
        "#la semilla se usa para hacerlo replicable    \n",
        "input_folder = '/content/drive/MyDrive/DOCTORADO/python/ADAM_10C_10A_npy/'\n",
        "splitfolders.ratio(input_folder, output='/content/drive/MyDrive/DOCTORADO/python/ADAM_10C_10A_TVT_npy', seed=1337, ratio=(.8, .1, .1), move=False ,group_prefix=None) \n"
      ],
      "metadata": {
        "id": "Ks18MZoJGXMm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}