{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdKwtOjLcOZ3b7bKYq0rOl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmcastillo/al112248/blob/main/modelo1_2_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he1raG8TN9jT",
        "outputId": "3e1c1459-7bc0-4b30-ced2-e43ba85e0ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (5.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install natsort"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/');\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate\n",
        "from scipy import ndimage\n",
        "import random\n",
        "import natsort\n",
        "import glob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRIWbDUTQFTZ",
        "outputId": "c3549306-376d-463b-e20e-1bcffc7664a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/train/50p_rand_50n/imgs/';\n",
        "train_mask_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/train/50p_rand_50n/masks/';\n",
        "\n",
        "train_img_list_temp = os.listdir(train_img_dir)\n",
        "#train_img_list = natsort.natsorted(train_img_list)\n",
        "train_mask_list_temp = os.listdir(train_mask_dir)\n",
        "#train_mask_list = natsort.natsorted(train_mask_list)\n",
        "\n",
        "#Se aleatoriza la lista del conjunto de entrenamiento\n",
        "train_img_list=[]\n",
        "train_mask_list=[]\n",
        "inx = random.sample(range(len(train_img_list_temp)), len(train_img_list_temp))  \n",
        "for i in range(len(inx)):\n",
        "  train_img_list.append(train_img_list_temp[inx[i]])\n",
        "  train_mask_list.append(train_mask_list_temp[inx[i]])\n",
        "\n",
        "val_img_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/val/imgs/';\n",
        "val_mask_dir = '/content/drive/MyDrive/DOCTORADO/python/datos_para_entrenar_modelos/modelo_1.X/val/masks/';\n",
        "val_img_list = os.listdir(val_img_dir)\n",
        "val_img_list = natsort.natsorted(val_img_list)\n",
        "val_mask_list = os.listdir(val_mask_dir)\n",
        "val_mask_list = natsort.natsorted(val_mask_list)"
      ],
      "metadata": {
        "id": "MruxLoBYQqFh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(img_dir, img_list):\n",
        "    images=[]\n",
        "    for i, image_name in enumerate(img_list):    \n",
        "        if (image_name.split('.')[1] == 'npy'):\n",
        "            \n",
        "            image = np.load(img_dir+image_name)\n",
        "                      \n",
        "            images.append(image)\n",
        "    images = np.array(images)\n",
        "    \n",
        "    return(images)"
      ],
      "metadata": {
        "id": "bTAaIf_5QPqC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U8qqs4WJwYwE"
      },
      "outputs": [],
      "source": [
        "def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n",
        "\n",
        "    L = len(img_list)\n",
        "\n",
        "    #keras needs the generator infinite, so we will use while true  \n",
        "    while True:\n",
        "\n",
        "        batch_start = 0\n",
        "        batch_end = batch_size\n",
        "\n",
        "        while batch_start < L:\n",
        "            limit = min(batch_end, L)\n",
        "                       \n",
        "            X = load_img(img_dir, img_list[batch_start:limit])\n",
        "            Y = load_img(mask_dir, mask_list[batch_start:limit])\n",
        "\n",
        "            X = X.astype(np.float32)  \n",
        "            Y = Y.astype(np.float32)\n",
        "\n",
        "            #I = img_list[batch_start:limit]\n",
        "            #M = mask_list[batch_start:limit]\n",
        "\n",
        "\n",
        "            yield (X,Y)#,I,M) #a tuple with two numpy arrays with batch_size samples\n",
        "           \n",
        "            batch_start += batch_size   \n",
        "            batch_end += batch_size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "\n",
        "train_img_datagen = imageLoader(train_img_dir, train_img_list, \n",
        "                                train_mask_dir, train_mask_list,batch_size)\n",
        "\n",
        "val_img_datagen = imageLoader(val_img_dir, val_img_list, \n",
        "                                val_mask_dir, val_mask_list,batch_size)\n"
      ],
      "metadata": {
        "id": "gwccjU68Qr7L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img,mask = train_img_datagen.__next__()\n",
        "print(img.shape)\n",
        "print(mask.shape)\n",
        "print(np.unique(mask))\n",
        "\n",
        "#Encuentra los patches 3D donde las máscaras contienen valores 1 y 0 (donde hay aneurisams)\n",
        "#if np.unique(mask).shape[0]  == 2:\n",
        "  #for i in range(mask.shape[0]):\n",
        "    #if np.unique(mask[i,:,:,:]).shape[0] == 2: \n",
        "      #n_patch_aneurisma = i\n",
        "      #print(f'En el patch número {n_patch_aneurisma+1} se encuentra el aneurisma')\n",
        "      #n_imagenes_aneurismas=[]\n",
        "      #for j in range(mask.shape[1]):\n",
        "        #if np.unique(mask[n_patch_aneurisma,j,:,:]).shape[0] == 2:\n",
        "          #print(f'En las imagenes {j+1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KHHIyA0zdAl",
        "outputId": "50230d0b-409b-48ba-f5f2-8603a60da782"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 64, 64, 64, 1)\n",
            "(4, 64, 64, 64, 1)\n",
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bv3JM39CV_tU"
      },
      "outputs": [],
      "source": [
        "def conv_block(input, num_filters):\n",
        "    x = Conv3D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)   #Not in the original network. \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv3D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)  #Not in the original network\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#Encoder block: Conv block followed by maxpooling\n",
        "\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPooling3D((2, 2, 2))(x)\n",
        "    return x, p   \n",
        "\n",
        "#Decoder block\n",
        "#skip features gets input from encoder for concatenation\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "#Build Unet using the blocks\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 16)\n",
        "    s2, p2 = encoder_block(p1, 32)\n",
        "    s3, p3 = encoder_block(p2, 64)\n",
        "    s4, p4 = encoder_block(p3, 128)\n",
        "\n",
        "    b1 = conv_block(p4, 256) #Bridge\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 128)\n",
        "    d2 = decoder_block(d1, s3, 64)\n",
        "    d3 = decoder_block(d2, s2, 32)\n",
        "    d4 = decoder_block(d3, s1, 16)\n",
        "\n",
        "    activation = 'sigmoid'\n",
        "\n",
        "    outputs = Conv3D(1, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n",
        "    print(f'activation function: {activation}')\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6qkE9MIgBYB",
        "outputId": "097120dc-eabc-4a4a-9555-2fe2753c4900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activation function: sigmoid\n",
            "model input shape: (None, 64, 64, 64, 1)\n"
          ]
        }
      ],
      "source": [
        "model = build_unet((64, 64, 64, 1))\n",
        "print(f'model input shape: {model.input_shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ant9LozBclBY",
        "outputId": "86e681be-4839-4c30-8bc8-2bae3334e241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation-models-3D\n",
            "  Downloading segmentation_models_3D-1.0.4-py3-none-any.whl (33 kB)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-3D) (2.9.2)\n",
            "Collecting classification-models-3D>=1.0.6\n",
            "  Downloading classification_models_3D-1.0.6-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->segmentation-models-3D) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->segmentation-models-3D) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (4.1.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.12)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (3.19.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.50.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.15.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (21.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (14.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.27.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->segmentation-models-3D) (2.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->segmentation-models-3D) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->segmentation-models-3D) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->segmentation-models-3D) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow>=2.8.0->segmentation-models-3D) (3.0.9)\n",
            "Installing collected packages: keras-applications, classification-models-3D, segmentation-models-3D\n",
            "Successfully installed classification-models-3D-1.0.6 keras-applications-1.0.8 segmentation-models-3D-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation-models-3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4-ffnnX2lDT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0bb1aa-e863-4490-c4a6-c12eb32fb569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ],
      "source": [
        "from segmentation_models_3D.losses import BinaryCELoss\n",
        "import segmentation_models_3D as sm\n",
        "from keras import backend as K\n",
        "\n",
        "'''\n",
        "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
        "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
        "'''\n",
        "dice_loss = sm.losses.DiceLoss()\n",
        "focal_loss = sm.losses.BinaryFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
        "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
        "\n",
        "iou = tf.keras.metrics.MeanIoU(num_classes=2)\n",
        "\n",
        "metrics = [iou, sm.metrics.FScore(), sm.metrics.Precision(), sm.metrics.Recall()]\n",
        "#jaccard_loss = sm.losses.JaccardLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg8cd8WeixXu",
        "outputId": "0c278841-9ca5-430c-b333-cde991f06b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 64, 64,  0           []                               \n",
            "                                 1)]                                                              \n",
            "                                                                                                  \n",
            " conv3d (Conv3D)                (None, 64, 64, 64,   448         ['input_1[0][0]']                \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 64, 64, 64,   64         ['conv3d[0][0]']                 \n",
            " alization)                     16)                                                               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 64, 64, 64,   0           ['batch_normalization[0][0]']    \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_1 (Conv3D)              (None, 64, 64, 64,   6928        ['activation[0][0]']             \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 64, 64, 64,   64         ['conv3d_1[0][0]']               \n",
            " rmalization)                   16)                                                               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 64, 64, 64,   0           ['batch_normalization_1[0][0]']  \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " max_pooling3d (MaxPooling3D)   (None, 32, 32, 32,   0           ['activation_1[0][0]']           \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_2 (Conv3D)              (None, 32, 32, 32,   13856       ['max_pooling3d[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 32,   128        ['conv3d_2[0][0]']               \n",
            " rmalization)                   32)                                                               \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32, 32, 32,   0           ['batch_normalization_2[0][0]']  \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_3 (Conv3D)              (None, 32, 32, 32,   27680       ['activation_2[0][0]']           \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 32,   128        ['conv3d_3[0][0]']               \n",
            " rmalization)                   32)                                                               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 32, 32,   0           ['batch_normalization_3[0][0]']  \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " max_pooling3d_1 (MaxPooling3D)  (None, 16, 16, 16,   0          ['activation_3[0][0]']           \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_4 (Conv3D)              (None, 16, 16, 16,   55360       ['max_pooling3d_1[0][0]']        \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 16,   256        ['conv3d_4[0][0]']               \n",
            " rmalization)                   64)                                                               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 16, 16, 16,   0           ['batch_normalization_4[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv3d_5 (Conv3D)              (None, 16, 16, 16,   110656      ['activation_4[0][0]']           \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 16,   256        ['conv3d_5[0][0]']               \n",
            " rmalization)                   64)                                                               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 16,   0           ['batch_normalization_5[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " max_pooling3d_2 (MaxPooling3D)  (None, 8, 8, 8, 64)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv3d_6 (Conv3D)              (None, 8, 8, 8, 128  221312      ['max_pooling3d_2[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 8, 8, 8, 128  512        ['conv3d_6[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 8, 8, 8, 128  0           ['batch_normalization_6[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_7 (Conv3D)              (None, 8, 8, 8, 128  442496      ['activation_6[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 8, 8, 8, 128  512        ['conv3d_7[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 8, 8, 8, 128  0           ['batch_normalization_7[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling3d_3 (MaxPooling3D)  (None, 4, 4, 4, 128  0          ['activation_7[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_8 (Conv3D)              (None, 4, 4, 4, 256  884992      ['max_pooling3d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 4, 4, 4, 256  1024       ['conv3d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 4, 4, 4, 256  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_9 (Conv3D)              (None, 4, 4, 4, 256  1769728     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 4, 4, 4, 256  1024       ['conv3d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 4, 4, 4, 256  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_transpose (Conv3DTransp  (None, 8, 8, 8, 128  262272     ['activation_9[0][0]']           \n",
            " ose)                           )                                                                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8, 8, 8, 256  0           ['conv3d_transpose[0][0]',       \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv3d_10 (Conv3D)             (None, 8, 8, 8, 128  884864      ['concatenate[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 8, 8, 8, 128  512        ['conv3d_10[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 8, 8, 8, 128  0           ['batch_normalization_10[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_11 (Conv3D)             (None, 8, 8, 8, 128  442496      ['activation_10[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 8, 8, 8, 128  512        ['conv3d_11[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 8, 8, 8, 128  0           ['batch_normalization_11[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3d_transpose_1 (Conv3DTran  (None, 16, 16, 16,   65600      ['activation_11[0][0]']          \n",
            " spose)                         64)                                                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 16, 16, 16,   0           ['conv3d_transpose_1[0][0]',     \n",
            "                                128)                              'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv3d_12 (Conv3D)             (None, 16, 16, 16,   221248      ['concatenate_1[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 16,   256        ['conv3d_12[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 16,   0           ['batch_normalization_12[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv3d_13 (Conv3D)             (None, 16, 16, 16,   110656      ['activation_12[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 16,   256        ['conv3d_13[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 16,   0           ['batch_normalization_13[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv3d_transpose_2 (Conv3DTran  (None, 32, 32, 32,   16416      ['activation_13[0][0]']          \n",
            " spose)                         32)                                                               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 32, 32, 32,   0           ['conv3d_transpose_2[0][0]',     \n",
            "                                64)                               'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv3d_14 (Conv3D)             (None, 32, 32, 32,   55328       ['concatenate_2[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 32, 32,   128        ['conv3d_14[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_14[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_15 (Conv3D)             (None, 32, 32, 32,   27680       ['activation_14[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 32, 32, 32,   128        ['conv3d_15[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_15[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv3d_transpose_3 (Conv3DTran  (None, 64, 64, 64,   4112       ['activation_15[0][0]']          \n",
            " spose)                         16)                                                               \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 64, 64, 64,   0           ['conv3d_transpose_3[0][0]',     \n",
            "                                32)                               'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv3d_16 (Conv3D)             (None, 64, 64, 64,   13840       ['concatenate_3[0][0]']          \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 64, 64, 64,   64         ['conv3d_16[0][0]']              \n",
            " ormalization)                  16)                                                               \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_16[0][0]'] \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_17 (Conv3D)             (None, 64, 64, 64,   6928        ['activation_16[0][0]']          \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 64, 64, 64,   64         ['conv3d_17[0][0]']              \n",
            " ormalization)                  16)                                                               \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_17[0][0]'] \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv3d_18 (Conv3D)             (None, 64, 64, 64,   17          ['activation_17[0][0]']          \n",
            "                                1)                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,650,801\n",
            "Trainable params: 5,647,857\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "LR = 0.001\n",
            "<segmentation_models_3D.base.objects.SumOfLosses object at 0x7f5510484310>\n"
          ]
        }
      ],
      "source": [
        "LR = 0.001\n",
        "optim = keras.optimizers.Adam(LR)\n",
        "\n",
        "loss = total_loss\n",
        "\n",
        "model.compile(optimizer=optim, loss=loss ,metrics = metrics)\n",
        "print(model.summary())\n",
        "print(f'LR = {LR}')\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5n_rIbVlQ5I",
        "outputId": "f9dac61d-5d61-4af5-f78d-2e1dfd4107d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "225/225 [==============================] - 20s 76ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 2/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 3/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 4/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 5/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 6/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 7/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 8/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 9/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 10/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 11/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 12/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 13/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 14/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 15/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 16/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 17/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 18/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 19/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 20/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 21/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 22/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 23/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 24/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 25/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 26/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 27/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 28/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 29/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 30/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 31/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 32/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 33/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 34/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 35/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 36/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 37/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 38/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 39/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 40/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 41/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 42/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 43/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 44/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 45/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 46/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 47/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 48/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 49/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 50/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 51/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 52/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 53/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 54/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 55/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 56/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 57/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 58/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 59/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 60/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 61/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 62/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 63/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 64/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 65/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 66/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 67/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 68/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 69/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 70/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 71/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 72/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 73/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 74/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 75/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 76/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 77/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 78/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 79/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 80/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 81/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 82/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 83/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 84/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 85/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 86/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 87/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 88/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 89/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 90/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 91/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 92/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 93/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 94/100\n",
            "225/225 [==============================] - 16s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 95/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 96/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 97/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 98/100\n",
            "225/225 [==============================] - 17s 74ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 99/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n",
            "Epoch 100/100\n",
            "225/225 [==============================] - 17s 73ms/step - loss: 0.9346 - mean_io_u: 0.4993 - f1-score: 0.0711 - precision: 1.0000 - recall: 0.0711 - val_loss: 0.0938 - val_mean_io_u: 0.5000 - val_f1-score: 0.9063 - val_precision: 1.0000 - val_recall: 0.9063\n"
          ]
        }
      ],
      "source": [
        "#Si uso el custom datagen\n",
        "steps_per_epoch = len(train_img_list)//batch_size\n",
        "val_steps_per_epoch = len(val_img_list)//batch_size\n",
        "\n",
        "history=model.fit(train_img_datagen,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          validation_data=val_img_datagen,\n",
        "          validation_steps=val_steps_per_epoch,\n",
        "          )\n",
        "\n",
        "model.save('modelo_1.2.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "#plot the training and validation IoU and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "f1 = history.history['f1-score']\n",
        "\n",
        "plt.plot(epochs, f1, 'y', label='Training f1')\n",
        "plt.title('Training and validation f1-score')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('f1-score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "JQAT07EfmcZg",
        "outputId": "c71c0428-a73f-47ae-e038-38bd2f0eb530"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZwdZWH28d/FhiRAMGCILyTQBIlAqLjIljctRmkVChq1CKSpRcUHQXlQFCnax5ai7adYK0pFLQhCEQFFsamg+AI8UEDMAhEIL5KG8CQpaAghECNC4Hr+mHvh5GQ32Qk72c3u9f189rMz99wz577PJOfamXvOjGwTERHRX1sMdgMiImLzkuCIiIhaEhwREVFLgiMiImpJcERERC0JjoiIqCXBEQNK0g8lHTPQdQeTpEWS/qSB7VrSrmX6a5I+3Z+6G/E6syX9eGPbuYFtnyDp15JWSZrQxGvE0KN8jyMkrWqZ3Rr4PfBsmf+g7Us2fauGDkmLgA/Y/ukAb9fANNsLBqqupCnAg8CWttcMRDvX81pbAk8A+9v+ZSn7DPAOYA/gs7ZPb7INMThGDXYDYvDZHtczvb4PSUmjmv4wis3Ky4GxwPyWsgXAqcDxg9KiFvn32pycqoo+SZohaYmkv5b0CPANSdtL+oGkZZJWlOnJLetcL+kDZfq9kv5L0udL3QclHbqRdadKukHSk5J+KukcSd/so939aeNnJN1UtvdjSTu0LH+PpIckLZf0N+t5f/aT9Iikjpayd0q6s0zvK+kWSY9LeljSlyWN7mNbF0r6bMv8J8o6/yPp/W11D5N0h6QnJC2WdHrL4hvK78fL6aMDet7blvUPlDRX0sry+8D+vjct9V4N3N/yWtcC2L7I9g+BJ/t631q2IUlnSfpN6ctdkv6wLNtK0r+U/bCy/NvYqix7u6T55X29XtIeLdtcVP693gn8VtIoSftLurnU/6WkGRtqW6xfgiM25BXAS4E/AI6j+jfzjTK/M/A74MvrWX8/qg+YHYDPAedL0kbU/RbwC2ACcDrwnvW8Zn/a+BfA+4CXAaOBUwAkTQe+Wra/Y3m9yfTC9q3Ab4E3t233W2X6WeDk0p8DgIOBD62n3ZQ2HFLa86fANKB9fOW3wF8B2wGHASdIekdZdlD5vZ3tcbZvadv2S4GrgLNL374AXKW1xyd6fW/a+v4rYM+W13pze51+eEtp76uB8cCRwPKy7PPAPsCBVP/+TgWeK4F1KfBRYCJwNfCfbYE8i+p92Y7qqOgq4LNlO6cA35U0cSPaG0WCIzbkOeDvbP/e9u9sL7f9XdurbT8J/APwxvWs/5Dt82w/C1wEvJLqP3O/60raGfgj4G9tP237v4A5fb1gP9v4Ddu/sv074NtAZyk/AviB7Rts/x74dHkP+nIp1QcVkrYF/qyUYfs22z+3vcb2IuDfemlHb44s7bvb9m+pgrK1f9fbvsv2c7bvLK/Xn+1C9YH6gO2LS7suBe4D3tZSp6/3ZqA9A2wL7E413nqv7YclbQG8H/iI7aW2n7V9c9kfRwFX2f6J7WeoAmYrqoDpcbbtxaX9fwlcbfvq8n79BOim2k+xkRIcsSHLbD/VMyNpa0n/Vk4hPEF1amS71tM1bR7pmbC9ukyOq1l3R+CxljKAxX01uJ9tfKRlenVLm3Zs3Xb54F5O374FvEvSGOBdwO22HyrteHU5TfZIacc/Uh19bMhabQAeauvffpKuK6fiVlKNJ/Rnuz3bfqit7CFgUst8X+/Ni1JOL60qP39s+1qqI8FzgN9IOlfSS6j6Mhb47w213/ZzVO9Va/tb37s/AN5dTlM9Lulx4A1Uf5TERkpwxIa0X3b3cWA3YD/bL+GFUyN9nX4aCA8DL5W0dUvZTuup/2La+HDrtstr9nmZqe17qD7IDmXt01RQnfK6j+pqqJcAn9qYNlCdbmv1Laojrp1sjwe+1rLdDV0m+T9UH6atdgaW9qNdL4rtPcvps3G2byxlZ9veB5hOdcrqE8CjwFPAq3rZzFrtL6cyd2prf+t7sBi42PZ2LT/b2P6nAe3cCJPgiLq2pRozeLycL/+7pl+w/AXfDZwuabSkA1j71MpAtvEK4HBJbyjnzc9gw/9PvgV8hCqgvtPWjieAVZJ2B07oZxu+DbxX0vQSXO3t35bqCOwpSftSBVaPZVSn1nbpY9tXA6+W9Bdl4Pgoqg/tH/SzbeslaUtJY6nes1GSxvZ1NCrpj8rR05ZU4zZPAc+Vo4gLgC9I2lFSRxnkH0P13hwm6eCy3sepLh+/uY8mfRN4m6S3lu2MVXXRR6/jVtE/CY6o64tU55QfBX4O/GgTve5sqgHm5VQDnZdTfWD0ZqPbaHs+8GGqMHgYWAEs2cBqPWMM19p+tKX8FKoP9SeB80qb+9OGH5Y+XEt1eeu1bVU+BJwh6Ungb6k+THvWXU01pnNTOTWzf9u2lwOHU33gLqcadD68rd0vxnlUoT0L+Jsy3deFDC8p9VdQHbUtB/65LDsFuAuYCzwGnAlsYft+qnGLf6Xav28D3mb76d5ewPZiYCbV0d4yqiOQT5DPvhclXwCMzZKky4H7bDd+xBMRa0vqxmahnNZ4laQtyuWqM4HvD3a7IkaifHM8NhevAL5HNVC9BDjB9h2D26SIkanRU1XlL8MvAR3A19uvZCiDXf9O9UWf5cBRthdJmk11HrLHXsDrbM+TdD3VpXS/K8veYvs3jXUiIiLW0lhwlCspfkX17dclVINcs8rliz11PgTsZft4SUcD77R9VNt2XgN83/aryvz1wCm2uxtpeERErFeTp6r2BRbYXggg6TKq89L3tNSZyQvfir0C+LIkee00mwVc9mIassMOO3jKlCkvZhMRESPObbfd9qjtdW7P0mRwTGLtb3AuoboXUa91bK8p34KdQHWZXY+jqAKm1TckPQt8l+rWzescNkk6jureSuy88850d+cAJSKiDkntdxkAhvhVVZL2A1bbvruleLbt1wB/XH56vUbc9rm2u2x3TZyY+5lFRAyUJoNjKWvfNmEy697W4Pk6kkZR3SGz9b5AR1NuGNfD9tLy+0mqL2ntO6CtjoiI9WoyOOYC01Q9R2E0VQi039F0DtDz6NAjqL55a4Byh8wjaRnfKLdI2KFMb0n1Ddi7iYiITaaxMY4yZnEicA3V5bgX2J4v6Qyg2/Yc4HzgYkkLqG4rcHTLJg4CFvcMrhdjgGtKaHQAP6W6ZUFEDGPPPPMMS5Ys4amnntpw5aht7NixTJ48mS233LJf9UfELUe6urqcwfGIzdeDDz7Itttuy4QJE+j7OWCxMWyzfPlynnzySaZOnbrWMkm32e5qX2dID45HRAA89dRTCY2GSGLChAm1juYSHBGxWUhoNKfue5vgiIiIWhIcEREbsHz5cjo7O+ns7OQVr3gFkyZNen7+6ad7fRTI87q7uznppJM2+BoHHnjgBuv016xZs9hrr70466yz+M53vsOee+7JFltsMWBfhM7dcSMiNmDChAnMmzcPgNNPP51x48ZxyimnPL98zZo1jBrV+8dpV1cXXV3rjC+v4+ab+3qIYT2PPPIIc+fOZcGCBQDce++9fO973+ODH/zggGwfcsQREbFR3vve93L88cez3377ceqpp/KLX/yCAw44gL333psDDzyQ+++/H4Drr7+eww8/HKhC5/3vfz8zZsxgl1124eyzz35+e+PGjXu+/owZMzjiiCPYfffdmT17Nj1Xv1599dXsvvvu7LPPPpx00knPb7fVW97yFpYuXUpnZyc33ngje+yxB7vtttuA9j1HHBGxWXnggY+yatW8Ad3muHGdTJv2xdrrLVmyhJtvvpmOjg6eeOIJbrzxRkaNGsVPf/pTPvWpT/Hd7353nXXuu+8+rrvuOp588kl22203TjjhhHW+P3HHHXcwf/58dtxxR17/+tdz00030dXVxQc/+EFuuOEGpk6dyqxZs3pt05w5czj88MOfP0JqQoIjImIjvfvd76ajowOAlStXcswxx/DAAw8giWeeeabXdQ477DDGjBnDmDFjeNnLXsavf/1rJk+evFadfffd9/myzs5OFi1axLhx49hll12e/67FrFmzOPfccxvsXd8SHBGxWdmYI4OmbLPNNs9Pf/rTn+ZNb3oTV155JYsWLWLGjBm9rjNmzJjnpzs6OlizZs1G1RlMGeOIiBgAK1euZNKkSQBceOGFA7793XbbjYULF7Jo0SIALr/88gF/jf5KcEREDIBTTz2VT37yk+y9996NHCFstdVWfOUrX+GQQw5hn332Ydttt2X8+PEbXO/KK69k8uTJ3HLLLRx22GG89a1vfdFtyb2qImLIu/fee9ljjz0GuxmDbtWqVYwbNw7bfPjDH2batGmcfPLJA7Lt3t7j3KsqImIzd95559HZ2cmee+7JypUrB/S7GXVkcDwiYjNx8sknD9gRxouRI46I2CyMhNPqg6Xue5vgiIghb+zYsSxfvjzh0YCe53GMHTu23+vkVFVEDHmTJ09myZIlLFu2bLCbMiz1PAGwvxIcETHkbbnllus8nS4GT05VRURELY0Gh6RDJN0vaYGk03pZPkbS5WX5rZKmlPLZkua1/DwnqbNt3TmS7m6y/RERsa7GgkNSB3AOcCgwHZglaXpbtWOBFbZ3Bc4CzgSwfYntTtudwHuAB23Pa9n2u4BVTbU9IiL61uQRx77AAtsLbT8NXAbMbKszE7ioTF8BHKx1H347q6wLgKRxwMeAzzbS6oiIWK8mg2MSsLhlfkkp67WO7TXASmBCW52jgEtb5j8D/Auwen0vLuk4Sd2SunMlRkTEwBnSg+OS9gNW2767zHcCr7J95YbWtX2u7S7bXRMnTmy6qRERI0aTwbEU2KllfnIp67WOpFHAeGB5y/KjWfto4wCgS9Ii4L+AV0u6fkBbHRER69VkcMwFpkmaKmk0VQjMaaszBzimTB8BXOvy1VBJWwBH0jK+Yfurtne0PQV4A/Ar2zMa7ENERLRp7AuAttdIOhG4BugALrA9X9IZQLftOcD5wMWSFgCPUYVLj4OAxbYXNtXGiIioL8/jiIiIXuV5HBERMSASHBERUUuCIyIiaklwRERELQmOiIioJcERERG1JDgiIqKWBEdERNSS4IiIiFoSHBERUUuCIyIiaklwRERELQmOiIioJcERERG1JDgiIqKWBEdERNSS4IiIiFoSHBERUUujwSHpEEn3S1og6bRelo+RdHlZfqukKaV8tqR5LT/PSeosy34k6ZeS5kv6mqSOJvsQERFrayw4ygf6OcChwHRglqTpbdWOBVbY3hU4CzgTwPYltjttdwLvAR60Pa+sc6Tt1wJ/CEwE3t1UHyIiYl1NHnHsCyywvdD208BlwMy2OjOBi8r0FcDBktRWZ1ZZFwDbT5TJUcBowAPd8IiI6FuTwTEJWNwyv6SU9VrH9hpgJTChrc5RwKWtBZKuAX4DPEkVOBERsYkM6cFxSfsBq23f3Vpu+63AK4ExwJv7WPc4Sd2SupctW9Z8YyMiRogmg2MpsFPL/ORS1msdSaOA8cDyluVH03a00cP2U8B/sO7pr57l59rust01ceLEjepARESsq8ngmAtMkzRV0miqEJjTVmcOcEyZPgK41rYBJG0BHEnL+IakcZJeWaZHAYcB9zXYh4iIaDOqqQ3bXiPpROAaoAO4wPZ8SWcA3bbnAOcDF0taADxGFS49DgIW217YUrYNMEfSGKrQuw74WlN9iIiIdan8gT+sdXV1ubu7e7CbERGxWZF0m+2u9vIhPTgeERFDT4IjIiJqSXBEREQtCY6IiKglwREREbUkOCIiopYER0RE1JLgiIiIWhIcERFRS4IjIiJqSXBEREQtCY6IiKglwREREbUkOCIiopYER0RE1JLgiIiIWhIcERFRS4IjIiJqSXBEREQtjQaHpEMk3S9pgaTTelk+RtLlZfmtkqaU8tmS5rX8PCepU9LWkq6SdJ+k+ZL+qcn2R0TEuhoLDkkdwDnAocB0YJak6W3VjgVW2N4VOAs4E8D2JbY7bXcC7wEetD2vrPN527sDewOvl3RoU32IiIh1NXnEsS+wwPZC208DlwEz2+rMBC4q01cAB0tSW51ZZV1sr7Z9XZl+GrgdmNxQ+yMiohdNBsckYHHL/JJS1msd22uAlcCEtjpHAZe2b1zSdsDbgJ/19uKSjpPULal72bJlG9WBiIhY15AeHJe0H7Da9t1t5aOowuRs2wt7W9f2uba7bHdNnDhxE7Q2ImJkaDI4lgI7tcxPLmW91ilhMB5Y3rL8aHo52gDOBR6w/cUBa21ERPRLk8ExF5gmaaqk0VQhMKetzhzgmDJ9BHCtbQNI2gI4kjK+0UPSZ6kC5qMNtj0iIvrQWHCUMYsTgWuAe4Fv254v6QxJby/VzgcmSFoAfAxovWT3IGBx66koSZOBv6G6Suv2cqnuB5rqQ0RErEvlD/xhraury93d3YPdjIiIzYqk22x3tZcP6cHxiIgYehIcERFRywaDQ9LLJZ0v6YdlfrqkY5tvWkREDEX9OeK4kGqAe8cy/ytyRVNExIjVn+DYwfa3gefg+aulnm20VRERMWT1Jzh+K2kC0PP9iv2pbg0SEREj0Kh+1PkY1Rf1XiXpJmAi1Zf1IiJiBFpvcJRbo7+x/OwGCLjf9jOboG0RETEErfdUle1ngVm219ieb/vuhEZExMjWn1NVN0n6MnA58NueQtu3N9aqiIgYsvoTHJ3l9xktZQbePPDNiYiIoW6DwWH7TZuiIRERsXnozzfHx0v6Qs/T9CT9i6Txm6JxEREx9PTnexwXAE9SPRvjSOAJ4BtNNioiIoau/oxxvMr2n7fM/72keU01KCIihrb+HHH8TtIbemYkvR74XXNNioiIoaw/RxwnABe1jGusAN7bWIsiImJI689VVfOA10p6SZl/ovFWRUTEkLXB4JD0j8DnbD9e5rcHPm77/zTduMH2wAMfZdWqDOdExOZp3LhOpk374oBvtz9jHIf2hAaA7RXAn/Vn45IOkXS/pAWSTutl+RhJl5flt0qaUspnS5rX8vOcpM6y7B8kLZa0qj9tiIiIgdWfMY4OSWNs/x5A0lbAmA2tVG6QeA7wp8ASYK6kObbvaal2LLDC9q6SjgbOBI6yfQlwSdnOa4Dvl1NmAP8JfBl4oF89fBGaSOqIiM1df444LgF+JunY8sjYnwAX9WO9fYEFthfafhq4DJjZVmdmy7auAA6WpLY6s8q6ANj+ue2H+/H6ERHRgP4Mjp8p6ZfAn5Siz9i+ph/bngQsbplfAuzXVx3bayStBCYAj7bUOYp1A2eDJB0HHAew88471109IiL60J9bjmwD/Nj2KcB5wBhJWzbesuq19wNW27677rq2z7XdZbtr4sSJDbQuImJk6s+pqhuAsZImAT8C3gNc2I/1lgI7tcxPLmW91pE0ChgPLG9ZfjRwaT9eKyIiNpH+BIdsrwbeBXzV9ruBPfux3lxgmqSpkkZThcCctjpzgGPK9BHAtbZ7nm2+BdW9sS4jIiKGjH4Fh6QDgNnAVaWsY0Mr2V4DnAhcA9wLfNv2fElnSHp7qXY+MEHSAqpnm7desnsQsNj2wrbGfE7SEmBrSUsknd6PPkRExABR+QO/7wrSQcApwE1loHwX4KO2T9oUDRwIXV1d7u7uHuxmRERsViTdZrurvbw/V1XdQDXOgaRXlCOAzSY0IiJiYPXnVFWrqxtpRUREbDbqBkf7l/MiImKEqRsc5zXSioiI2GzUCg7bXwGQNK6Z5kRExFBX94ijxz0brhIREcNRn1dVSfpYX4uAHHFERIxQ6zvi+Edge2Dbtp9xG1gvIiKGsfV9j+N2qudg3Na+QNIHmmtSREQMZes7clgKPCTpI70sW+ebhBERMTKsLzimA6OB90vaXtJLe36AZzZN8yIiYqhZ36mqfwN+BuwC3MbaX/5zKY+IiBGmzyMO22fb3gO4wPYutqe2/CQ0IiJGqA1eHWX7hE3RkIiI2DzkstqIiKglwREREbUkOCIiopYER0RE1JLgiIiIWhoNDkmHSLpf0gJJp/WyfIyky8vyWyVNKeWzJc1r+XlOUmdZto+ku8o6Z0vKw6UiIjahxoJDUgdwDnAo1bfQZ0ma3lbtWGCF7V2Bs4AzAWxfYrvTdifwHuBB2/PKOl8F/hcwrfwc0lQfIiJiXU0ecewLLLC90PbTwGXAzLY6M4GLyvQVwMG9HEHMKusi6ZXAS2z/3LaBfwfe0VQHIiJiXU0GxyRgccv8klLWax3ba4CVwIS2OkcBl7bUX7KBbQIg6ThJ3ZK6ly1btlEdiIiIdQ3pwXFJ+wGrbd9dd13b59rust01ceLEBloXETEyNRkcS4GdWuYnl7Je60gaBYwHlrcsP5oXjjZ66k/ewDYjIqJBTQbHXGCapKmSRlOFwJy2OnOAY8r0EcC1ZewCSVsAR1LGNwBsPww8IWn/MhbyV8B/NNiHiIhos77bqr8ottdIOhG4BuigusvufElnAN225wDnAxdLWgA8RhUuPQ4CFtte2LbpDwEXAlsBPyw/ERGxiaj8gT+sdXV1ubu7e7CbERGxWZF0m+11nvg6pAfHIyJi6ElwRERELQmOiIioJcERERG1JDgiIqKWBEdERNSS4IiIiFoSHBERUUuCIyIiaklwRERELQmOiIioJcERERG1JDgiIqKWBEdERNSS4IiIiFoSHBERUUuCIyIiaklwRERELQmOiIiopdHgkHSIpPslLZB0Wi/Lx0i6vCy/VdKUlmV7SbpF0nxJd0kaW8qPknRnKT+zyfZHRMS6GgsOSR3AOcChwHRglqTpbdWOBVbY3hU4CzizrDsK+CZwvO09gRnAM5ImAP8MHFzKXyHp4Kb6EBER62ryiGNfYIHthbafBi4DZrbVmQlcVKavAA6WJOAtwJ22fwlge7ntZ4FdgAdsLyvr/BT48wb7EBERbZoMjknA4pb5JaWs1zq21wArgQnAqwFLukbS7ZJOLfUXALtJmlKOSt4B7NTbi0s6TlK3pO5ly5b1ViUiIjbCUB0cHwW8AZhdfr9T0sG2VwAnAJcDNwKLgGd724Dtc2132e6aOHHipml1RMQI0GRwLGXto4HJpazXOuUIYjywnOro5Abbj9peDVwNvA7A9n/a3s/2AcD9wK8a7ENERLRpMjjmAtMkTZU0GjgamNNWZw5wTJk+ArjWtoFrgNdI2roEyhuBewAkvaz83h74EPD1BvsQERFtRjW1YdtrJJ1IFQIdwAW250s6A+i2PQc4H7hY0gLgMapwwfYKSV+gCh8DV9u+qmz6S5JeW6bPsJ0jjoiITUjVH/jDW1dXl7u7uwe7GRERmxVJt9nuai8fqoPjERExRCU4IiKilgRHRETUkuCIiIhaEhwREVFLgiMiImpJcERERC0JjoiIqCXBERERtSQ4IiKilgRHRETUkuCIiIhaEhwREVFLgiMiImpJcERERC0JjoiIqCXBERERtSQ4IiKilkaDQ9Ihku6XtEDSab0sHyPp8rL8VklTWpbtJekWSfMl3SVpbCmfVebvlPQjSTs02YeIiFhbY8EhqQM4BzgUmA7MkjS9rdqxwArbuwJnAWeWdUcB3wSOt70nMAN4ppR/CXiT7b2AO4ETm+pDRESsq8kjjn2BBbYX2n4auAyY2VZnJnBRmb4COFiSgLcAd9r+JYDt5bafBVR+tin1XgL8T4N9iIiINk0GxyRgccv8klLWax3ba4CVwATg1YAlXSPpdkmnljrPACcAd1EFxnTg/Ab7EBERbYbq4Pgo4A3A7PL7nZIOlrQlVXDsDexIdarqk71tQNJxkroldS9btmwTNTsiYvhrMjiWAju1zE8uZb3WKeMX44HlVEcnN9h+1PZq4GrgdUAngO3/tm3g28CBvb247XNtd9numjhx4sD1KiJihGsyOOYC0yRNlTQaOBqY01ZnDnBMmT4CuLYEwjXAayRtXQLljcA9VEEzXVJPEvwpcG+DfYiIiDajmtqw7TWSTqQKgQ7gAtvzJZ0BdNueQzU+cbGkBcBjVOGC7RWSvkAVPgautn0VgKS/B26Q9AzwEPDepvoQERHrUvUH/vDW1dXl7u7uwW5GRMRmRdJttrvay4fq4HhERAxRCY6IiKglwREREbUkOCIiopYER0RE1JLgiIiIWhIcERFRS4IjIiJqSXBEREQtCY6IiKglwREREbUkOCIiopYER0RE1JLgiIiIWhIcERFRS4IjIiJqSXBEREQtI+IJgJKWUT1mtr92AB5tqDlD1UjsM4zMfo/EPsPI7PeL7fMf2J7YXjgigqMuSd29PS5xOBuJfYaR2e+R2GcYmf1uqs85VRUREbUkOCIiopYER+/OHewGDIKR2GcYmf0eiX2GkdnvRvqcMY6IiKglRxwREVFLgiMiImpJcLSQdIik+yUtkHTaYLenKZJ2knSdpHskzZf0kVL+Ukk/kfRA+b39YLd1oEnqkHSHpB+U+amSbi37/HJJowe7jQNN0naSrpB0n6R7JR0w3Pe1pJPLv+27JV0qaexw3NeSLpD0G0l3t5T1um9VObv0/05Jr9vY101wFJI6gHOAQ4HpwCxJ0we3VY1ZA3zc9nRgf+DDpa+nAT+zPQ34WZkfbj4C3NsyfyZwlu1dgRXAsYPSqmZ9CfiR7d2B11L1f9jua0mTgJOALtt/CHQARzM89/WFwCFtZX3t20OBaeXnOOCrG/uiCY4X7AsssL3Q9tPAZcDMQW5TI2w/bPv2Mv0k1QfJJKr+XlSqXQS8Y3Ba2AxJk4HDgK+XeQFvBq4oVYZjn8cDBwHnA9h+2vbjDPN9DYwCtpI0CtgaeJhhuK9t3wA81lbc176dCfy7Kz8HtpP0yo153QTHCyYBi1vml5SyYU3SFGBv4Fbg5bYfLoseAV4+SM1qyheBU4HnyvwE4HHba8r8cNznU4FlwDfKKbqvS9qGYbyvbS8FPg/8P6rAWAncxvDf1z362rcD9hmX4BjBJI0Dvgt81PYTrctcXac9bK7VlnQ48Bvbtw12WzaxUcDrgK/a3hv4LW2npYbhvt6e6q/rqcCOwDasezpnRGhq3yY4XrAU2KllfnIpG5YkbUkVGpfY/l4p/nXPoWv5/ZvBal8DXjMs+SwAAAMlSURBVA+8XdIiqtOQb6Y6979dOZ0Bw3OfLwGW2L61zF9BFSTDeV//CfCg7WW2nwG+R7X/h/u+7tHXvh2wz7gExwvmAtPKlRejqQbT5gxymxpRzu2fD9xr+wsti+YAx5TpY4D/2NRta4rtT9qebHsK1b691vZs4DrgiFJtWPUZwPYjwGJJu5Wig4F7GMb7muoU1f6Sti7/1nv6PKz3dYu+9u0c4K/K1VX7AytbTmnVkm+Ot5D0Z1TnwTuAC2z/wyA3qRGS3gDcCNzFC+f7P0U1zvFtYGeq29Afabt94G2zJ2kGcIrtwyXtQnUE8lLgDuAvbf9+MNs30CR1Ul0QMBpYCLyP6o/GYbuvJf09cBTVFYR3AB+gOp8/rPa1pEuBGVS3T/818HfA9+ll35YQ/TLVabvVwPtsd2/U6yY4IiKijpyqioiIWhIcERFRS4IjIiJqSXBEREQtCY6IiKglwRGxkSQ9K2ley8+A3ShQ0pTWO55GDCWjNlwlIvrwO9udg92IiE0tRxwRA0zSIkmfk3SXpF9I2rWUT5F0bXkWws8k7VzKXy7pSkm/LD8Hlk11SDqvPFfix5K2KvVPUvUslTslXTZI3YwRLMERsfG2ajtVdVTLspW2X0P1Td0vlrJ/BS6yvRdwCXB2KT8b+L+2X0t1H6n5pXwacI7tPYHHgT8v5acBe5ftHN9U5yL6km+OR2wkSatsj+ulfBHwZtsLy80kH7E9QdKjwCttP1PKH7a9g6RlwOTW21+U293/pDyMB0l/DWxp+7OSfgSsorq1xPdtr2q4qxFryRFHRDPcx3QdrfdRepYXxiQPo3pa5euAuS13fI3YJBIcEc04quX3LWX6Zqo78wLMprrRJFSP9zwBnn8m+vi+NippC2An29cBfw2MB9Y56oloUv5Sidh4W0ma1zL/I9s9l+RuL+lOqqOGWaXsf1M9ie8TVE/le18p/whwrqRjqY4sTqB6cl1vOoBvlnARcHZ5FGzEJpMxjogBVsY4umw/OthtiWhCTlVFREQtOeKIiIhacsQRERG1JDgiIqKWBEdERNSS4IiIiFoSHBERUcv/BxQdueEGv9ftAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}