{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmcastillo/al112248/blob/main/Unet_aneurismas_custom_datagen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GieFQU-yp91T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/');\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate\n",
        "from scipy import ndimage\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRbQnF1MM3M_"
      },
      "outputs": [],
      "source": [
        "def load_img(img_dir, img_list):\n",
        "    images=[]\n",
        "    for i, image_name in enumerate(img_list):    \n",
        "        if (image_name.split('.')[1] == 'npy'):\n",
        "            \n",
        "            image = np.load(img_dir+image_name)\n",
        "                      \n",
        "            images.append(image)\n",
        "    images = np.array(images)\n",
        "    \n",
        "    return(images)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n",
        "\n",
        "    L = len(img_list)\n",
        "\n",
        "    #keras needs the generator infinite, so we will use while true  \n",
        "    while True:\n",
        "\n",
        "        batch_start = 0\n",
        "        batch_end = batch_size\n",
        "\n",
        "        while batch_start < L:\n",
        "            limit = min(batch_end, L)\n",
        "                       \n",
        "            X = load_img(img_dir, img_list[batch_start:limit])\n",
        "            Y = load_img(mask_dir, mask_list[batch_start:limit])\n",
        "\n",
        "            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     \n",
        "\n",
        "            batch_start += batch_size   \n",
        "            batch_end += batch_size"
      ],
      "metadata": {
        "id": "U8qqs4WJwYwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_dir = '/content/drive/MyDrive/DOCTORADO/python/ADAM_10C_10A_npy/imgs/';\n",
        "train_mask_dir = '/content/drive/MyDrive/DOCTORADO/python/ADAM_10C_10A_npy/masks/';\n",
        "train_img_list = os.listdir(train_img_dir)\n",
        "train_mask_list = os.listdir(train_mask_dir)\n",
        "\n",
        "val_img_dir = '/content/drive/MyDrive/DOCTORADO/python/val/imgs/';\n",
        "val_mask_dir = '/content/drive/MyDrive/DOCTORADO/python/val/masks/';\n",
        "val_img_list = os.listdir(val_img_dir)\n",
        "val_mask_list = os.listdir(val_mask_dir)\n"
      ],
      "metadata": {
        "id": "nnJlIDfV5nUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "\n",
        "train_img_datagen = imageLoader(train_img_dir, train_img_list, \n",
        "                                train_mask_dir, train_mask_list, batch_size)\n",
        "\n",
        "val_img_datagen = imageLoader(val_img_dir, val_img_list, \n",
        "                                val_mask_dir, val_mask_list, batch_size)\n"
      ],
      "metadata": {
        "id": "OxMZEJJB6GYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img,mask=train_img_datagen.__next__()\n",
        "print(img.shape)\n",
        "print(mask.shape)"
      ],
      "metadata": {
        "id": "yLohaBVxz9wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(input, num_filters):\n",
        "    x = Conv3D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)   #Not in the original network. \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv3D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)  #Not in the original network\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#Encoder block: Conv block followed by maxpooling\n",
        "\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPooling3D((2, 2, 2))(x)\n",
        "    return x, p   \n",
        "\n",
        "#Decoder block\n",
        "#skip features gets input from encoder for concatenation\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "#Build Unet using the blocks\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 16)\n",
        "    s2, p2 = encoder_block(p1, 32)\n",
        "    s3, p3 = encoder_block(p2, 64)\n",
        "    s4, p4 = encoder_block(p3, 128)\n",
        "\n",
        "    b1 = conv_block(p4, 256) #Bridge\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 128)\n",
        "    d2 = decoder_block(d1, s3, 64)\n",
        "    d3 = decoder_block(d2, s2, 32)\n",
        "    d4 = decoder_block(d3, s1, 16)\n",
        "\n",
        "    activation = 'softmax'\n",
        "\n",
        "    outputs = Conv3D(1, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n",
        "    print(f'activation function: {activation}')\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "bv3JM39CV_tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_unet((64, 64, 64, 1))\n",
        "print(f'model input shape: {model.input_shape}')"
      ],
      "metadata": {
        "id": "u6qkE9MIgBYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models-3D"
      ],
      "metadata": {
        "id": "ant9LozBclBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_3D as sm\n",
        "from keras import backend as K\n",
        "\n",
        "'''\n",
        "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
        "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
        "dice_loss = sm.losses.DiceLoss()\n",
        "focal_loss = sm.losses.BinaryFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
        "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
        "'''\n",
        "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
        "jaccard_loss = sm.losses.JaccardLoss()\n"
      ],
      "metadata": {
        "id": "4-ffnnX2lDT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.0001\n",
        "optim = keras.optimizers.Adam(LR)\n",
        "\n",
        "model.compile(optimizer=optim, loss=jaccard_loss ,metrics = metrics)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "Cg8cd8WeixXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Si uso el custom datagen\n",
        "steps_per_epoch = len(train_img_list)//batch_size\n",
        "val_steps_per_epoch = len(val_img_list)//batch_size\n",
        "\n",
        "history=model.fit(train_img_datagen,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=val_img_datagen,\n",
        "          validation_steps=val_steps_per_epoch,\n",
        "          )\n",
        "\n",
        "model.save('UNet_aneurismas_patches.hdf5')"
      ],
      "metadata": {
        "id": "q5n_rIbVlQ5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test)\n",
        "#y_pred = y_pred >= 0.5 \n",
        "#y_pred = y_pred.astype(int)\n",
        "print(y_pred.shape)\n",
        "print(np.unique(y_pred))"
      ],
      "metadata": {
        "id": "1lmgaxe9m3YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_test[38,:,:,26,:]))"
      ],
      "metadata": {
        "id": "1g5KlvQhFc7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1,3,1)\n",
        "plt.imshow(X_test[38,:,:,26,0],cmap='gray');\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(y_test[38,:,:,26,0],cmap='gray');\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(y_pred[38,:,:,26,0],cmap='gray');"
      ],
      "metadata": {
        "id": "rXKSjagzd7Y8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}